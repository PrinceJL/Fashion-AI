{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4bd0a7d5-49b6-4f3c-9a4a-fd53eb3bac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEN-Denim-id_00000080-01_7_additional.jpg',\n",
       " 'MEN-Denim-id_00000089-01_7_additional.jpg',\n",
       " 'MEN-Denim-id_00000089-02_7_additional.jpg',\n",
       " 'MEN-Denim-id_00000089-03_7_additional.jpg',\n",
       " 'MEN-Denim-id_00000089-04_7_additional.jpg']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Filter valid images with corresponding masks and shape labels\n",
    "import os\n",
    "\n",
    "# Paths to image, mask, and shape label files\n",
    "base_path = \"../DeepFashionData\"\n",
    "img_dir = os.path.join(base_path, \"images\")\n",
    "segm_dir = os.path.join(base_path, \"segm\")\n",
    "shape_path = os.path.join(base_path, \"labels\", \"shape\", \"shape_anno_all.txt\")\n",
    "\n",
    "# Load shape labels\n",
    "def load_shape_labels(shape_path):\n",
    "    labels = {}\n",
    "    with open(shape_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                img_name = parts[0].split(\"/\")[-1]\n",
    "                labels[img_name] = int(parts[1])\n",
    "    return labels\n",
    "\n",
    "shape_labels = load_shape_labels(shape_path)\n",
    "\n",
    "# Get valid images (those with masks and shape labels)\n",
    "valid_images = []\n",
    "for img_name in os.listdir(img_dir):\n",
    "    if img_name.endswith(\".jpg\"):  # Check for jpg files\n",
    "        mask_name = img_name.replace(\".jpg\", \"_segm.png\")\n",
    "        if os.path.exists(os.path.join(segm_dir, mask_name)) and img_name in shape_labels:\n",
    "            valid_images.append(img_name)\n",
    "\n",
    "# Check first 5 valid images\n",
    "valid_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b5ca2d4-7105-4668-b5a7-8487e78325d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Dataset Class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class ClothingSegmDataset(Dataset):\n",
    "    def __init__(self, img_dir, segm_dir, shape_labels, valid_images, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.segm_dir = segm_dir\n",
    "        self.shape_labels = shape_labels\n",
    "        self.valid_images = valid_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.valid_images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        mask_path = os.path.join(self.segm_dir, img_name.replace(\".jpg\", \"_segm.png\"))\n",
    "\n",
    "        # Load image and mask\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        # Get shape label\n",
    "        shape_label = self.shape_labels.get(img_name, -1)\n",
    "\n",
    "        return image, mask, torch.tensor(shape_label)\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = ClothingSegmDataset(img_dir, segm_dir, shape_labels, valid_images, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc36de6a-ad91-4a7c-95d3-cacb251f0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Model Class\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "class ShapeClassificationModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ShapeClassificationModel, self).__init__()\n",
    "        self.segmentation = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1  # Segmentation output (binary mask)\n",
    "        )\n",
    "        self.classification_base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.classification_base.fc = nn.Identity()  # Removing the final classification layer\n",
    "\n",
    "        # Add custom head for shape classification\n",
    "        self.shape_head = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seg_out = self.segmentation(x)  # Get segmentation output\n",
    "        features = self.classification_base(x)  # Extract features using ResNet18\n",
    "        shape_out = self.shape_head(features)  # Shape classification output\n",
    "        return seg_out, shape_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3dde9cda-f7ae-4edb-9dd8-6abc1beac4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "  Batch 10/1428 - Total Loss: 1.7612, Cls Loss: 1.2492, Seg Loss: 0.5121\n",
      "  Batch 20/1428 - Total Loss: 1.2787, Cls Loss: 0.8454, Seg Loss: 0.4333\n",
      "  Batch 30/1428 - Total Loss: 0.6584, Cls Loss: 0.2950, Seg Loss: 0.3633\n",
      "  Batch 40/1428 - Total Loss: 0.8535, Cls Loss: 0.5296, Seg Loss: 0.3239\n",
      "  Batch 50/1428 - Total Loss: 0.9618, Cls Loss: 0.6377, Seg Loss: 0.3240\n",
      "  Batch 60/1428 - Total Loss: 0.6712, Cls Loss: 0.3729, Seg Loss: 0.2982\n",
      "  Batch 70/1428 - Total Loss: 0.9424, Cls Loss: 0.6668, Seg Loss: 0.2756\n",
      "  Batch 80/1428 - Total Loss: 1.0082, Cls Loss: 0.7366, Seg Loss: 0.2716\n",
      "  Batch 90/1428 - Total Loss: 0.8628, Cls Loss: 0.6160, Seg Loss: 0.2468\n",
      "  Batch 100/1428 - Total Loss: 0.7117, Cls Loss: 0.4785, Seg Loss: 0.2332\n",
      "  Batch 110/1428 - Total Loss: 0.5179, Cls Loss: 0.2741, Seg Loss: 0.2437\n",
      "  Batch 120/1428 - Total Loss: 1.0751, Cls Loss: 0.8505, Seg Loss: 0.2246\n",
      "  Batch 130/1428 - Total Loss: 0.5253, Cls Loss: 0.3073, Seg Loss: 0.2181\n",
      "  Batch 140/1428 - Total Loss: 0.4805, Cls Loss: 0.2749, Seg Loss: 0.2056\n",
      "  Batch 150/1428 - Total Loss: 0.6783, Cls Loss: 0.4666, Seg Loss: 0.2117\n",
      "  Batch 160/1428 - Total Loss: 0.7010, Cls Loss: 0.4945, Seg Loss: 0.2065\n",
      "  Batch 170/1428 - Total Loss: 0.8268, Cls Loss: 0.6273, Seg Loss: 0.1995\n",
      "  Batch 180/1428 - Total Loss: 0.2736, Cls Loss: 0.0809, Seg Loss: 0.1927\n",
      "  Batch 190/1428 - Total Loss: 0.3522, Cls Loss: 0.1616, Seg Loss: 0.1906\n",
      "  Batch 200/1428 - Total Loss: 0.7837, Cls Loss: 0.6046, Seg Loss: 0.1791\n",
      "  Batch 210/1428 - Total Loss: 1.1888, Cls Loss: 1.0033, Seg Loss: 0.1855\n",
      "  Batch 220/1428 - Total Loss: 0.3041, Cls Loss: 0.1108, Seg Loss: 0.1934\n",
      "  Batch 230/1428 - Total Loss: 0.3978, Cls Loss: 0.2128, Seg Loss: 0.1850\n",
      "  Batch 240/1428 - Total Loss: 0.4735, Cls Loss: 0.3010, Seg Loss: 0.1725\n",
      "  Batch 250/1428 - Total Loss: 0.6578, Cls Loss: 0.4867, Seg Loss: 0.1711\n",
      "  Batch 260/1428 - Total Loss: 0.2939, Cls Loss: 0.0993, Seg Loss: 0.1946\n",
      "  Batch 270/1428 - Total Loss: 0.3057, Cls Loss: 0.1419, Seg Loss: 0.1638\n",
      "  Batch 280/1428 - Total Loss: 0.4081, Cls Loss: 0.2455, Seg Loss: 0.1625\n",
      "  Batch 290/1428 - Total Loss: 0.3578, Cls Loss: 0.1840, Seg Loss: 0.1739\n",
      "  Batch 300/1428 - Total Loss: 0.6849, Cls Loss: 0.5228, Seg Loss: 0.1622\n",
      "  Batch 310/1428 - Total Loss: 0.3829, Cls Loss: 0.2333, Seg Loss: 0.1496\n",
      "  Batch 320/1428 - Total Loss: 0.3617, Cls Loss: 0.2005, Seg Loss: 0.1611\n",
      "  Batch 330/1428 - Total Loss: 0.7043, Cls Loss: 0.5425, Seg Loss: 0.1618\n",
      "  Batch 340/1428 - Total Loss: 0.3482, Cls Loss: 0.1773, Seg Loss: 0.1709\n",
      "  Batch 350/1428 - Total Loss: 0.6239, Cls Loss: 0.4788, Seg Loss: 0.1450\n",
      "  Batch 360/1428 - Total Loss: 0.7608, Cls Loss: 0.5926, Seg Loss: 0.1683\n",
      "  Batch 370/1428 - Total Loss: 0.6012, Cls Loss: 0.4506, Seg Loss: 0.1506\n",
      "  Batch 380/1428 - Total Loss: 1.0430, Cls Loss: 0.9046, Seg Loss: 0.1384\n",
      "  Batch 390/1428 - Total Loss: 0.6684, Cls Loss: 0.5168, Seg Loss: 0.1515\n",
      "  Batch 400/1428 - Total Loss: 0.4653, Cls Loss: 0.3172, Seg Loss: 0.1481\n",
      "  Batch 410/1428 - Total Loss: 0.7454, Cls Loss: 0.5988, Seg Loss: 0.1466\n",
      "  Batch 420/1428 - Total Loss: 1.2484, Cls Loss: 1.1117, Seg Loss: 0.1367\n",
      "  Batch 430/1428 - Total Loss: 1.2496, Cls Loss: 1.1132, Seg Loss: 0.1364\n",
      "  Batch 440/1428 - Total Loss: 0.3395, Cls Loss: 0.2091, Seg Loss: 0.1304\n",
      "  Batch 450/1428 - Total Loss: 0.5281, Cls Loss: 0.3778, Seg Loss: 0.1503\n",
      "  Batch 460/1428 - Total Loss: 0.4248, Cls Loss: 0.2903, Seg Loss: 0.1346\n",
      "  Batch 470/1428 - Total Loss: 0.4112, Cls Loss: 0.2745, Seg Loss: 0.1368\n",
      "  Batch 480/1428 - Total Loss: 0.2289, Cls Loss: 0.1049, Seg Loss: 0.1240\n",
      "  Batch 490/1428 - Total Loss: 1.1499, Cls Loss: 1.0192, Seg Loss: 0.1308\n",
      "  Batch 500/1428 - Total Loss: 0.6741, Cls Loss: 0.5422, Seg Loss: 0.1318\n",
      "  Batch 510/1428 - Total Loss: 0.3551, Cls Loss: 0.2223, Seg Loss: 0.1328\n",
      "  Batch 520/1428 - Total Loss: 0.2163, Cls Loss: 0.0801, Seg Loss: 0.1362\n",
      "  Batch 530/1428 - Total Loss: 0.2323, Cls Loss: 0.0985, Seg Loss: 0.1338\n",
      "  Batch 540/1428 - Total Loss: 2.3378, Cls Loss: 2.1867, Seg Loss: 0.1511\n",
      "  Batch 550/1428 - Total Loss: 0.1920, Cls Loss: 0.0571, Seg Loss: 0.1349\n",
      "  Batch 560/1428 - Total Loss: 0.1801, Cls Loss: 0.0494, Seg Loss: 0.1307\n",
      "  Batch 570/1428 - Total Loss: 0.3366, Cls Loss: 0.2184, Seg Loss: 0.1182\n",
      "  Batch 580/1428 - Total Loss: 1.3008, Cls Loss: 1.1698, Seg Loss: 0.1310\n",
      "  Batch 590/1428 - Total Loss: 0.6951, Cls Loss: 0.5694, Seg Loss: 0.1258\n",
      "  Batch 600/1428 - Total Loss: 0.5021, Cls Loss: 0.3838, Seg Loss: 0.1183\n",
      "  Batch 610/1428 - Total Loss: 0.2048, Cls Loss: 0.0840, Seg Loss: 0.1209\n",
      "  Batch 620/1428 - Total Loss: 0.3474, Cls Loss: 0.2266, Seg Loss: 0.1207\n",
      "  Batch 630/1428 - Total Loss: 0.6201, Cls Loss: 0.5075, Seg Loss: 0.1126\n",
      "  Batch 640/1428 - Total Loss: 0.1581, Cls Loss: 0.0408, Seg Loss: 0.1173\n",
      "  Batch 650/1428 - Total Loss: 0.1566, Cls Loss: 0.0228, Seg Loss: 0.1338\n",
      "  Batch 660/1428 - Total Loss: 0.2589, Cls Loss: 0.1255, Seg Loss: 0.1334\n",
      "  Batch 670/1428 - Total Loss: 0.1831, Cls Loss: 0.0683, Seg Loss: 0.1148\n",
      "  Batch 680/1428 - Total Loss: 0.8395, Cls Loss: 0.7126, Seg Loss: 0.1269\n",
      "  Batch 690/1428 - Total Loss: 0.1993, Cls Loss: 0.0776, Seg Loss: 0.1216\n",
      "  Batch 700/1428 - Total Loss: 0.1829, Cls Loss: 0.0683, Seg Loss: 0.1146\n",
      "  Batch 710/1428 - Total Loss: 0.1947, Cls Loss: 0.0722, Seg Loss: 0.1226\n",
      "  Batch 720/1428 - Total Loss: 0.1528, Cls Loss: 0.0277, Seg Loss: 0.1251\n",
      "  Batch 730/1428 - Total Loss: 0.8380, Cls Loss: 0.7232, Seg Loss: 0.1148\n",
      "  Batch 740/1428 - Total Loss: 0.3410, Cls Loss: 0.2310, Seg Loss: 0.1100\n",
      "  Batch 750/1428 - Total Loss: 0.3529, Cls Loss: 0.2314, Seg Loss: 0.1215\n",
      "  Batch 760/1428 - Total Loss: 0.3017, Cls Loss: 0.1882, Seg Loss: 0.1135\n",
      "  Batch 770/1428 - Total Loss: 0.1492, Cls Loss: 0.0326, Seg Loss: 0.1166\n",
      "  Batch 780/1428 - Total Loss: 0.2597, Cls Loss: 0.1506, Seg Loss: 0.1090\n",
      "  Batch 790/1428 - Total Loss: 0.2951, Cls Loss: 0.1784, Seg Loss: 0.1168\n",
      "  Batch 800/1428 - Total Loss: 0.2936, Cls Loss: 0.1722, Seg Loss: 0.1214\n",
      "  Batch 810/1428 - Total Loss: 0.7057, Cls Loss: 0.5783, Seg Loss: 0.1273\n",
      "  Batch 820/1428 - Total Loss: 0.3386, Cls Loss: 0.2144, Seg Loss: 0.1242\n",
      "  Batch 830/1428 - Total Loss: 0.5468, Cls Loss: 0.4457, Seg Loss: 0.1012\n",
      "  Batch 840/1428 - Total Loss: 1.3845, Cls Loss: 1.2699, Seg Loss: 0.1146\n",
      "  Batch 850/1428 - Total Loss: 1.0499, Cls Loss: 0.9354, Seg Loss: 0.1145\n",
      "  Batch 860/1428 - Total Loss: 0.5548, Cls Loss: 0.4436, Seg Loss: 0.1112\n",
      "  Batch 870/1428 - Total Loss: 0.1969, Cls Loss: 0.0711, Seg Loss: 0.1258\n",
      "  Batch 880/1428 - Total Loss: 0.2354, Cls Loss: 0.1229, Seg Loss: 0.1126\n",
      "  Batch 890/1428 - Total Loss: 0.4209, Cls Loss: 0.3097, Seg Loss: 0.1112\n",
      "  Batch 900/1428 - Total Loss: 0.7303, Cls Loss: 0.6212, Seg Loss: 0.1090\n",
      "  Batch 910/1428 - Total Loss: 0.2525, Cls Loss: 0.1305, Seg Loss: 0.1220\n",
      "  Batch 920/1428 - Total Loss: 0.3563, Cls Loss: 0.2366, Seg Loss: 0.1197\n",
      "  Batch 930/1428 - Total Loss: 0.1999, Cls Loss: 0.0815, Seg Loss: 0.1185\n",
      "  Batch 940/1428 - Total Loss: 0.2648, Cls Loss: 0.1478, Seg Loss: 0.1170\n",
      "  Batch 950/1428 - Total Loss: 0.2170, Cls Loss: 0.0932, Seg Loss: 0.1238\n",
      "  Batch 960/1428 - Total Loss: 0.4016, Cls Loss: 0.2828, Seg Loss: 0.1189\n",
      "  Batch 970/1428 - Total Loss: 0.2424, Cls Loss: 0.1107, Seg Loss: 0.1317\n",
      "  Batch 980/1428 - Total Loss: 0.2942, Cls Loss: 0.1703, Seg Loss: 0.1238\n",
      "  Batch 990/1428 - Total Loss: 0.2651, Cls Loss: 0.1475, Seg Loss: 0.1176\n",
      "  Batch 1000/1428 - Total Loss: 0.2092, Cls Loss: 0.1015, Seg Loss: 0.1077\n",
      "  Batch 1010/1428 - Total Loss: 1.1127, Cls Loss: 1.0014, Seg Loss: 0.1112\n",
      "  Batch 1020/1428 - Total Loss: 0.2370, Cls Loss: 0.1205, Seg Loss: 0.1166\n",
      "  Batch 1030/1428 - Total Loss: 0.2416, Cls Loss: 0.1293, Seg Loss: 0.1123\n",
      "  Batch 1040/1428 - Total Loss: 0.1268, Cls Loss: 0.0262, Seg Loss: 0.1006\n",
      "  Batch 1050/1428 - Total Loss: 0.1645, Cls Loss: 0.0620, Seg Loss: 0.1025\n",
      "  Batch 1060/1428 - Total Loss: 0.1656, Cls Loss: 0.0601, Seg Loss: 0.1055\n",
      "  Batch 1070/1428 - Total Loss: 0.2813, Cls Loss: 0.1759, Seg Loss: 0.1054\n",
      "  Batch 1080/1428 - Total Loss: 0.3269, Cls Loss: 0.2225, Seg Loss: 0.1044\n",
      "  Batch 1090/1428 - Total Loss: 0.3664, Cls Loss: 0.2593, Seg Loss: 0.1071\n",
      "  Batch 1100/1428 - Total Loss: 0.2310, Cls Loss: 0.1141, Seg Loss: 0.1169\n",
      "  Batch 1110/1428 - Total Loss: 0.3463, Cls Loss: 0.2328, Seg Loss: 0.1136\n",
      "  Batch 1120/1428 - Total Loss: 0.3496, Cls Loss: 0.2419, Seg Loss: 0.1077\n",
      "  Batch 1130/1428 - Total Loss: 0.1996, Cls Loss: 0.0916, Seg Loss: 0.1080\n",
      "  Batch 1140/1428 - Total Loss: 0.4461, Cls Loss: 0.3381, Seg Loss: 0.1081\n",
      "  Batch 1150/1428 - Total Loss: 0.2398, Cls Loss: 0.1308, Seg Loss: 0.1090\n",
      "  Batch 1160/1428 - Total Loss: 0.3039, Cls Loss: 0.2070, Seg Loss: 0.0968\n",
      "  Batch 1170/1428 - Total Loss: 0.2317, Cls Loss: 0.1275, Seg Loss: 0.1042\n",
      "  Batch 1180/1428 - Total Loss: 0.2669, Cls Loss: 0.1493, Seg Loss: 0.1176\n",
      "  Batch 1190/1428 - Total Loss: 0.2451, Cls Loss: 0.1324, Seg Loss: 0.1127\n",
      "  Batch 1200/1428 - Total Loss: 0.1285, Cls Loss: 0.0266, Seg Loss: 0.1019\n",
      "  Batch 1210/1428 - Total Loss: 1.1012, Cls Loss: 0.9919, Seg Loss: 0.1093\n",
      "  Batch 1220/1428 - Total Loss: 0.1476, Cls Loss: 0.0362, Seg Loss: 0.1114\n",
      "  Batch 1230/1428 - Total Loss: 0.1446, Cls Loss: 0.0349, Seg Loss: 0.1098\n",
      "  Batch 1240/1428 - Total Loss: 0.1925, Cls Loss: 0.0857, Seg Loss: 0.1068\n",
      "  Batch 1250/1428 - Total Loss: 0.1483, Cls Loss: 0.0420, Seg Loss: 0.1062\n",
      "  Batch 1260/1428 - Total Loss: 0.2103, Cls Loss: 0.1038, Seg Loss: 0.1065\n",
      "  Batch 1270/1428 - Total Loss: 0.5820, Cls Loss: 0.4783, Seg Loss: 0.1038\n",
      "  Batch 1280/1428 - Total Loss: 0.1463, Cls Loss: 0.0446, Seg Loss: 0.1017\n",
      "  Batch 1290/1428 - Total Loss: 0.1441, Cls Loss: 0.0497, Seg Loss: 0.0944\n",
      "  Batch 1300/1428 - Total Loss: 0.1842, Cls Loss: 0.0850, Seg Loss: 0.0991\n",
      "  Batch 1310/1428 - Total Loss: 0.1473, Cls Loss: 0.0430, Seg Loss: 0.1043\n",
      "  Batch 1320/1428 - Total Loss: 0.2871, Cls Loss: 0.1831, Seg Loss: 0.1040\n",
      "  Batch 1330/1428 - Total Loss: 0.2775, Cls Loss: 0.1623, Seg Loss: 0.1151\n",
      "  Batch 1340/1428 - Total Loss: 0.2089, Cls Loss: 0.1016, Seg Loss: 0.1074\n",
      "  Batch 1350/1428 - Total Loss: 0.4674, Cls Loss: 0.3651, Seg Loss: 0.1023\n",
      "  Batch 1360/1428 - Total Loss: 0.4628, Cls Loss: 0.3476, Seg Loss: 0.1152\n",
      "  Batch 1370/1428 - Total Loss: 0.6509, Cls Loss: 0.5330, Seg Loss: 0.1179\n",
      "  Batch 1380/1428 - Total Loss: 0.3465, Cls Loss: 0.2267, Seg Loss: 0.1198\n",
      "  Batch 1390/1428 - Total Loss: 0.2869, Cls Loss: 0.1733, Seg Loss: 0.1137\n",
      "  Batch 1400/1428 - Total Loss: 1.0743, Cls Loss: 0.9771, Seg Loss: 0.0973\n",
      "  Batch 1410/1428 - Total Loss: 0.1520, Cls Loss: 0.0343, Seg Loss: 0.1177\n",
      "  Batch 1420/1428 - Total Loss: 0.2147, Cls Loss: 0.1121, Seg Loss: 0.1025\n",
      "  Batch 1428/1428 - Total Loss: 0.1862, Cls Loss: 0.0765, Seg Loss: 0.1097\n",
      "Epoch 1 Summary - Avg Total Loss: 0.4896, Avg Cls Loss: 0.3422, Avg Seg Loss: 0.1474\n",
      "\n",
      "Epoch 2/5\n",
      "  Batch 10/1428 - Total Loss: 0.1325, Cls Loss: 0.0262, Seg Loss: 0.1063\n",
      "  Batch 20/1428 - Total Loss: 0.2352, Cls Loss: 0.1245, Seg Loss: 0.1107\n",
      "  Batch 30/1428 - Total Loss: 0.4686, Cls Loss: 0.3661, Seg Loss: 0.1025\n",
      "  Batch 40/1428 - Total Loss: 0.6434, Cls Loss: 0.5338, Seg Loss: 0.1095\n",
      "  Batch 50/1428 - Total Loss: 0.1452, Cls Loss: 0.0467, Seg Loss: 0.0985\n",
      "  Batch 60/1428 - Total Loss: 0.1520, Cls Loss: 0.0458, Seg Loss: 0.1062\n",
      "  Batch 70/1428 - Total Loss: 0.4001, Cls Loss: 0.2991, Seg Loss: 0.1010\n",
      "  Batch 80/1428 - Total Loss: 0.1677, Cls Loss: 0.0340, Seg Loss: 0.1337\n",
      "  Batch 90/1428 - Total Loss: 0.1772, Cls Loss: 0.0568, Seg Loss: 0.1204\n",
      "  Batch 100/1428 - Total Loss: 0.2311, Cls Loss: 0.1289, Seg Loss: 0.1022\n",
      "  Batch 110/1428 - Total Loss: 0.1477, Cls Loss: 0.0409, Seg Loss: 0.1068\n",
      "  Batch 120/1428 - Total Loss: 0.3379, Cls Loss: 0.2274, Seg Loss: 0.1104\n",
      "  Batch 130/1428 - Total Loss: 0.5803, Cls Loss: 0.4725, Seg Loss: 0.1078\n",
      "  Batch 140/1428 - Total Loss: 1.5446, Cls Loss: 1.4365, Seg Loss: 0.1081\n",
      "  Batch 150/1428 - Total Loss: 0.2016, Cls Loss: 0.0929, Seg Loss: 0.1087\n",
      "  Batch 160/1428 - Total Loss: 0.7797, Cls Loss: 0.6821, Seg Loss: 0.0976\n",
      "  Batch 170/1428 - Total Loss: 0.1515, Cls Loss: 0.0558, Seg Loss: 0.0957\n",
      "  Batch 180/1428 - Total Loss: 0.1717, Cls Loss: 0.0627, Seg Loss: 0.1089\n",
      "  Batch 190/1428 - Total Loss: 0.9178, Cls Loss: 0.8260, Seg Loss: 0.0918\n",
      "  Batch 200/1428 - Total Loss: 0.4002, Cls Loss: 0.2964, Seg Loss: 0.1037\n",
      "  Batch 210/1428 - Total Loss: 0.1396, Cls Loss: 0.0240, Seg Loss: 0.1156\n",
      "  Batch 220/1428 - Total Loss: 0.1573, Cls Loss: 0.0443, Seg Loss: 0.1130\n",
      "  Batch 230/1428 - Total Loss: 0.2255, Cls Loss: 0.1180, Seg Loss: 0.1075\n",
      "  Batch 240/1428 - Total Loss: 0.2876, Cls Loss: 0.1780, Seg Loss: 0.1096\n",
      "  Batch 250/1428 - Total Loss: 0.1166, Cls Loss: 0.0182, Seg Loss: 0.0984\n",
      "  Batch 260/1428 - Total Loss: 0.1155, Cls Loss: 0.0175, Seg Loss: 0.0980\n",
      "  Batch 270/1428 - Total Loss: 0.1170, Cls Loss: 0.0149, Seg Loss: 0.1021\n",
      "  Batch 280/1428 - Total Loss: 0.2045, Cls Loss: 0.1028, Seg Loss: 0.1018\n",
      "  Batch 290/1428 - Total Loss: 0.1516, Cls Loss: 0.0496, Seg Loss: 0.1020\n",
      "  Batch 300/1428 - Total Loss: 0.1262, Cls Loss: 0.0241, Seg Loss: 0.1020\n",
      "  Batch 310/1428 - Total Loss: 0.1181, Cls Loss: 0.0155, Seg Loss: 0.1026\n",
      "  Batch 320/1428 - Total Loss: 0.1146, Cls Loss: 0.0171, Seg Loss: 0.0975\n",
      "  Batch 330/1428 - Total Loss: 0.2970, Cls Loss: 0.1955, Seg Loss: 0.1014\n",
      "  Batch 340/1428 - Total Loss: 0.2020, Cls Loss: 0.0948, Seg Loss: 0.1073\n",
      "  Batch 350/1428 - Total Loss: 0.1246, Cls Loss: 0.0242, Seg Loss: 0.1004\n",
      "  Batch 360/1428 - Total Loss: 0.1495, Cls Loss: 0.0494, Seg Loss: 0.1001\n",
      "  Batch 370/1428 - Total Loss: 0.1156, Cls Loss: 0.0148, Seg Loss: 0.1008\n",
      "  Batch 380/1428 - Total Loss: 0.1999, Cls Loss: 0.0921, Seg Loss: 0.1078\n",
      "  Batch 390/1428 - Total Loss: 0.1404, Cls Loss: 0.0236, Seg Loss: 0.1168\n",
      "  Batch 400/1428 - Total Loss: 0.1303, Cls Loss: 0.0255, Seg Loss: 0.1048\n",
      "  Batch 410/1428 - Total Loss: 0.1757, Cls Loss: 0.0727, Seg Loss: 0.1030\n",
      "  Batch 420/1428 - Total Loss: 0.1648, Cls Loss: 0.0693, Seg Loss: 0.0955\n",
      "  Batch 430/1428 - Total Loss: 1.1144, Cls Loss: 1.0092, Seg Loss: 0.1052\n",
      "  Batch 440/1428 - Total Loss: 1.2228, Cls Loss: 1.1210, Seg Loss: 0.1018\n",
      "  Batch 450/1428 - Total Loss: 0.1956, Cls Loss: 0.0833, Seg Loss: 0.1123\n",
      "  Batch 460/1428 - Total Loss: 0.2229, Cls Loss: 0.1188, Seg Loss: 0.1041\n",
      "  Batch 470/1428 - Total Loss: 1.0711, Cls Loss: 0.9760, Seg Loss: 0.0951\n",
      "  Batch 480/1428 - Total Loss: 0.2630, Cls Loss: 0.1613, Seg Loss: 0.1017\n",
      "  Batch 490/1428 - Total Loss: 0.1602, Cls Loss: 0.0515, Seg Loss: 0.1087\n",
      "  Batch 500/1428 - Total Loss: 0.3878, Cls Loss: 0.2874, Seg Loss: 0.1004\n",
      "  Batch 510/1428 - Total Loss: 0.1933, Cls Loss: 0.0958, Seg Loss: 0.0975\n",
      "  Batch 520/1428 - Total Loss: 0.3101, Cls Loss: 0.2080, Seg Loss: 0.1021\n",
      "  Batch 530/1428 - Total Loss: 0.1962, Cls Loss: 0.1011, Seg Loss: 0.0951\n",
      "  Batch 540/1428 - Total Loss: 0.1417, Cls Loss: 0.0209, Seg Loss: 0.1208\n",
      "  Batch 550/1428 - Total Loss: 0.1820, Cls Loss: 0.0807, Seg Loss: 0.1013\n",
      "  Batch 560/1428 - Total Loss: 0.1936, Cls Loss: 0.0856, Seg Loss: 0.1080\n",
      "  Batch 570/1428 - Total Loss: 0.1220, Cls Loss: 0.0243, Seg Loss: 0.0976\n",
      "  Batch 580/1428 - Total Loss: 0.4534, Cls Loss: 0.3526, Seg Loss: 0.1008\n",
      "  Batch 590/1428 - Total Loss: 0.6598, Cls Loss: 0.5639, Seg Loss: 0.0960\n",
      "  Batch 600/1428 - Total Loss: 0.1597, Cls Loss: 0.0581, Seg Loss: 0.1016\n",
      "  Batch 610/1428 - Total Loss: 0.4277, Cls Loss: 0.3331, Seg Loss: 0.0945\n",
      "  Batch 620/1428 - Total Loss: 0.3127, Cls Loss: 0.2108, Seg Loss: 0.1019\n",
      "  Batch 630/1428 - Total Loss: 0.1889, Cls Loss: 0.0818, Seg Loss: 0.1071\n",
      "  Batch 640/1428 - Total Loss: 0.3917, Cls Loss: 0.2880, Seg Loss: 0.1037\n",
      "  Batch 650/1428 - Total Loss: 0.1651, Cls Loss: 0.0645, Seg Loss: 0.1006\n",
      "  Batch 660/1428 - Total Loss: 0.1384, Cls Loss: 0.0251, Seg Loss: 0.1133\n",
      "  Batch 670/1428 - Total Loss: 0.1578, Cls Loss: 0.0673, Seg Loss: 0.0906\n",
      "  Batch 680/1428 - Total Loss: 0.1105, Cls Loss: 0.0082, Seg Loss: 0.1023\n",
      "  Batch 690/1428 - Total Loss: 0.2489, Cls Loss: 0.1420, Seg Loss: 0.1069\n",
      "  Batch 700/1428 - Total Loss: 0.4725, Cls Loss: 0.3786, Seg Loss: 0.0939\n",
      "  Batch 710/1428 - Total Loss: 0.1355, Cls Loss: 0.0320, Seg Loss: 0.1035\n",
      "  Batch 720/1428 - Total Loss: 0.6627, Cls Loss: 0.5617, Seg Loss: 0.1010\n",
      "  Batch 730/1428 - Total Loss: 0.5860, Cls Loss: 0.4922, Seg Loss: 0.0938\n",
      "  Batch 740/1428 - Total Loss: 0.2331, Cls Loss: 0.1213, Seg Loss: 0.1117\n",
      "  Batch 750/1428 - Total Loss: 0.1646, Cls Loss: 0.0617, Seg Loss: 0.1028\n",
      "  Batch 760/1428 - Total Loss: 0.1427, Cls Loss: 0.0393, Seg Loss: 0.1034\n",
      "  Batch 770/1428 - Total Loss: 0.5179, Cls Loss: 0.4251, Seg Loss: 0.0928\n",
      "  Batch 780/1428 - Total Loss: 0.3840, Cls Loss: 0.2770, Seg Loss: 0.1069\n",
      "  Batch 790/1428 - Total Loss: 0.2996, Cls Loss: 0.1938, Seg Loss: 0.1058\n",
      "  Batch 800/1428 - Total Loss: 0.3914, Cls Loss: 0.2753, Seg Loss: 0.1161\n",
      "  Batch 810/1428 - Total Loss: 0.2753, Cls Loss: 0.1692, Seg Loss: 0.1061\n",
      "  Batch 820/1428 - Total Loss: 0.2245, Cls Loss: 0.1227, Seg Loss: 0.1018\n",
      "  Batch 830/1428 - Total Loss: 0.1370, Cls Loss: 0.0381, Seg Loss: 0.0989\n",
      "  Batch 840/1428 - Total Loss: 0.2255, Cls Loss: 0.1180, Seg Loss: 0.1075\n",
      "  Batch 850/1428 - Total Loss: 0.3912, Cls Loss: 0.2913, Seg Loss: 0.0999\n",
      "  Batch 860/1428 - Total Loss: 1.0000, Cls Loss: 0.8895, Seg Loss: 0.1105\n",
      "  Batch 870/1428 - Total Loss: 0.2854, Cls Loss: 0.1733, Seg Loss: 0.1121\n",
      "  Batch 880/1428 - Total Loss: 0.3672, Cls Loss: 0.2723, Seg Loss: 0.0949\n",
      "  Batch 890/1428 - Total Loss: 0.4268, Cls Loss: 0.3197, Seg Loss: 0.1070\n",
      "  Batch 900/1428 - Total Loss: 0.6039, Cls Loss: 0.5089, Seg Loss: 0.0949\n",
      "  Batch 910/1428 - Total Loss: 0.1233, Cls Loss: 0.0178, Seg Loss: 0.1056\n",
      "  Batch 920/1428 - Total Loss: 0.1700, Cls Loss: 0.0609, Seg Loss: 0.1091\n",
      "  Batch 930/1428 - Total Loss: 0.1625, Cls Loss: 0.0529, Seg Loss: 0.1097\n",
      "  Batch 940/1428 - Total Loss: 0.1642, Cls Loss: 0.0633, Seg Loss: 0.1009\n",
      "  Batch 950/1428 - Total Loss: 0.4734, Cls Loss: 0.3658, Seg Loss: 0.1075\n",
      "  Batch 960/1428 - Total Loss: 0.5099, Cls Loss: 0.4149, Seg Loss: 0.0950\n",
      "  Batch 970/1428 - Total Loss: 0.1418, Cls Loss: 0.0474, Seg Loss: 0.0945\n",
      "  Batch 980/1428 - Total Loss: 0.5150, Cls Loss: 0.4055, Seg Loss: 0.1095\n",
      "  Batch 990/1428 - Total Loss: 0.1690, Cls Loss: 0.0718, Seg Loss: 0.0972\n",
      "  Batch 1000/1428 - Total Loss: 0.5746, Cls Loss: 0.4844, Seg Loss: 0.0902\n",
      "  Batch 1010/1428 - Total Loss: 0.3013, Cls Loss: 0.2064, Seg Loss: 0.0950\n",
      "  Batch 1020/1428 - Total Loss: 0.1824, Cls Loss: 0.0871, Seg Loss: 0.0953\n",
      "  Batch 1030/1428 - Total Loss: 0.1268, Cls Loss: 0.0147, Seg Loss: 0.1121\n",
      "  Batch 1040/1428 - Total Loss: 0.1999, Cls Loss: 0.0861, Seg Loss: 0.1138\n",
      "  Batch 1050/1428 - Total Loss: 0.6464, Cls Loss: 0.5497, Seg Loss: 0.0968\n",
      "  Batch 1060/1428 - Total Loss: 0.1222, Cls Loss: 0.0273, Seg Loss: 0.0949\n",
      "  Batch 1070/1428 - Total Loss: 0.1387, Cls Loss: 0.0246, Seg Loss: 0.1141\n",
      "  Batch 1080/1428 - Total Loss: 0.2717, Cls Loss: 0.1811, Seg Loss: 0.0906\n",
      "  Batch 1090/1428 - Total Loss: 0.1752, Cls Loss: 0.0718, Seg Loss: 0.1034\n",
      "  Batch 1100/1428 - Total Loss: 1.2236, Cls Loss: 1.1300, Seg Loss: 0.0936\n",
      "  Batch 1110/1428 - Total Loss: 0.1324, Cls Loss: 0.0343, Seg Loss: 0.0981\n",
      "  Batch 1120/1428 - Total Loss: 0.4671, Cls Loss: 0.3667, Seg Loss: 0.1004\n",
      "  Batch 1130/1428 - Total Loss: 0.5673, Cls Loss: 0.4154, Seg Loss: 0.1520\n",
      "  Batch 1140/1428 - Total Loss: 0.1290, Cls Loss: 0.0235, Seg Loss: 0.1055\n",
      "  Batch 1150/1428 - Total Loss: 0.2764, Cls Loss: 0.1827, Seg Loss: 0.0936\n",
      "  Batch 1160/1428 - Total Loss: 0.1470, Cls Loss: 0.0481, Seg Loss: 0.0990\n",
      "  Batch 1170/1428 - Total Loss: 0.4125, Cls Loss: 0.3132, Seg Loss: 0.0993\n",
      "  Batch 1180/1428 - Total Loss: 0.9370, Cls Loss: 0.8164, Seg Loss: 0.1206\n",
      "  Batch 1190/1428 - Total Loss: 0.3493, Cls Loss: 0.2415, Seg Loss: 0.1078\n",
      "  Batch 1200/1428 - Total Loss: 0.1366, Cls Loss: 0.0333, Seg Loss: 0.1033\n",
      "  Batch 1210/1428 - Total Loss: 0.8576, Cls Loss: 0.7645, Seg Loss: 0.0931\n",
      "  Batch 1220/1428 - Total Loss: 0.1425, Cls Loss: 0.0395, Seg Loss: 0.1029\n",
      "  Batch 1230/1428 - Total Loss: 0.1827, Cls Loss: 0.0857, Seg Loss: 0.0970\n",
      "  Batch 1240/1428 - Total Loss: 0.1230, Cls Loss: 0.0281, Seg Loss: 0.0949\n",
      "  Batch 1250/1428 - Total Loss: 0.1758, Cls Loss: 0.0502, Seg Loss: 0.1256\n",
      "  Batch 1260/1428 - Total Loss: 0.2583, Cls Loss: 0.1575, Seg Loss: 0.1008\n",
      "  Batch 1270/1428 - Total Loss: 0.1522, Cls Loss: 0.0526, Seg Loss: 0.0996\n",
      "  Batch 1280/1428 - Total Loss: 0.2201, Cls Loss: 0.1117, Seg Loss: 0.1084\n",
      "  Batch 1290/1428 - Total Loss: 0.1344, Cls Loss: 0.0378, Seg Loss: 0.0966\n",
      "  Batch 1300/1428 - Total Loss: 0.1886, Cls Loss: 0.0908, Seg Loss: 0.0978\n",
      "  Batch 1310/1428 - Total Loss: 0.5584, Cls Loss: 0.4658, Seg Loss: 0.0926\n",
      "  Batch 1320/1428 - Total Loss: 0.4842, Cls Loss: 0.3706, Seg Loss: 0.1136\n",
      "  Batch 1330/1428 - Total Loss: 0.1214, Cls Loss: 0.0253, Seg Loss: 0.0961\n",
      "  Batch 1340/1428 - Total Loss: 0.1302, Cls Loss: 0.0327, Seg Loss: 0.0974\n",
      "  Batch 1350/1428 - Total Loss: 0.1649, Cls Loss: 0.0704, Seg Loss: 0.0946\n",
      "  Batch 1360/1428 - Total Loss: 0.1676, Cls Loss: 0.0656, Seg Loss: 0.1020\n",
      "  Batch 1370/1428 - Total Loss: 0.1264, Cls Loss: 0.0247, Seg Loss: 0.1017\n",
      "  Batch 1380/1428 - Total Loss: 0.1420, Cls Loss: 0.0433, Seg Loss: 0.0987\n",
      "  Batch 1390/1428 - Total Loss: 0.1521, Cls Loss: 0.0449, Seg Loss: 0.1072\n",
      "  Batch 1400/1428 - Total Loss: 0.5647, Cls Loss: 0.4677, Seg Loss: 0.0969\n",
      "  Batch 1410/1428 - Total Loss: 0.1913, Cls Loss: 0.0859, Seg Loss: 0.1054\n",
      "  Batch 1420/1428 - Total Loss: 0.3317, Cls Loss: 0.2251, Seg Loss: 0.1066\n",
      "  Batch 1428/1428 - Total Loss: 0.4618, Cls Loss: 0.3649, Seg Loss: 0.0969\n",
      "Epoch 2 Summary - Avg Total Loss: 0.3052, Avg Cls Loss: 0.2008, Avg Seg Loss: 0.1044\n",
      "\n",
      "Epoch 3/5\n",
      "  Batch 10/1428 - Total Loss: 0.1196, Cls Loss: 0.0132, Seg Loss: 0.1064\n",
      "  Batch 20/1428 - Total Loss: 0.4465, Cls Loss: 0.3557, Seg Loss: 0.0908\n",
      "  Batch 30/1428 - Total Loss: 0.1599, Cls Loss: 0.0576, Seg Loss: 0.1023\n",
      "  Batch 40/1428 - Total Loss: 0.5526, Cls Loss: 0.4587, Seg Loss: 0.0940\n",
      "  Batch 50/1428 - Total Loss: 0.1366, Cls Loss: 0.0290, Seg Loss: 0.1077\n",
      "  Batch 60/1428 - Total Loss: 0.1079, Cls Loss: 0.0092, Seg Loss: 0.0987\n",
      "  Batch 70/1428 - Total Loss: 0.3030, Cls Loss: 0.2112, Seg Loss: 0.0919\n",
      "  Batch 80/1428 - Total Loss: 0.2837, Cls Loss: 0.1798, Seg Loss: 0.1038\n",
      "  Batch 90/1428 - Total Loss: 0.3376, Cls Loss: 0.2408, Seg Loss: 0.0968\n",
      "  Batch 100/1428 - Total Loss: 0.2106, Cls Loss: 0.1039, Seg Loss: 0.1067\n",
      "  Batch 110/1428 - Total Loss: 0.3404, Cls Loss: 0.2428, Seg Loss: 0.0976\n",
      "  Batch 120/1428 - Total Loss: 0.2291, Cls Loss: 0.1255, Seg Loss: 0.1036\n",
      "  Batch 130/1428 - Total Loss: 0.1415, Cls Loss: 0.0480, Seg Loss: 0.0934\n",
      "  Batch 140/1428 - Total Loss: 0.1627, Cls Loss: 0.0551, Seg Loss: 0.1076\n",
      "  Batch 150/1428 - Total Loss: 0.2100, Cls Loss: 0.1097, Seg Loss: 0.1003\n",
      "  Batch 160/1428 - Total Loss: 0.1334, Cls Loss: 0.0300, Seg Loss: 0.1034\n",
      "  Batch 170/1428 - Total Loss: 0.1125, Cls Loss: 0.0110, Seg Loss: 0.1015\n",
      "  Batch 180/1428 - Total Loss: 0.1264, Cls Loss: 0.0258, Seg Loss: 0.1006\n",
      "  Batch 190/1428 - Total Loss: 0.1541, Cls Loss: 0.0539, Seg Loss: 0.1002\n",
      "  Batch 200/1428 - Total Loss: 0.1091, Cls Loss: 0.0183, Seg Loss: 0.0908\n",
      "  Batch 210/1428 - Total Loss: 0.1298, Cls Loss: 0.0340, Seg Loss: 0.0958\n",
      "  Batch 220/1428 - Total Loss: 0.1195, Cls Loss: 0.0152, Seg Loss: 0.1043\n",
      "  Batch 230/1428 - Total Loss: 0.5049, Cls Loss: 0.4002, Seg Loss: 0.1046\n",
      "  Batch 240/1428 - Total Loss: 0.1603, Cls Loss: 0.0664, Seg Loss: 0.0939\n",
      "  Batch 250/1428 - Total Loss: 0.1172, Cls Loss: 0.0241, Seg Loss: 0.0931\n",
      "  Batch 260/1428 - Total Loss: 0.1420, Cls Loss: 0.0386, Seg Loss: 0.1034\n",
      "  Batch 270/1428 - Total Loss: 0.1785, Cls Loss: 0.0807, Seg Loss: 0.0978\n",
      "  Batch 280/1428 - Total Loss: 0.2265, Cls Loss: 0.1191, Seg Loss: 0.1074\n",
      "  Batch 290/1428 - Total Loss: 0.1539, Cls Loss: 0.0517, Seg Loss: 0.1022\n",
      "  Batch 300/1428 - Total Loss: 0.4360, Cls Loss: 0.3394, Seg Loss: 0.0966\n",
      "  Batch 310/1428 - Total Loss: 0.7726, Cls Loss: 0.6695, Seg Loss: 0.1032\n",
      "  Batch 320/1428 - Total Loss: 0.4737, Cls Loss: 0.3657, Seg Loss: 0.1080\n",
      "  Batch 330/1428 - Total Loss: 0.1219, Cls Loss: 0.0079, Seg Loss: 0.1140\n",
      "  Batch 340/1428 - Total Loss: 0.1243, Cls Loss: 0.0226, Seg Loss: 0.1016\n",
      "  Batch 350/1428 - Total Loss: 0.1377, Cls Loss: 0.0421, Seg Loss: 0.0956\n",
      "  Batch 360/1428 - Total Loss: 0.1152, Cls Loss: 0.0197, Seg Loss: 0.0955\n",
      "  Batch 370/1428 - Total Loss: 0.1079, Cls Loss: 0.0131, Seg Loss: 0.0948\n",
      "  Batch 380/1428 - Total Loss: 0.3285, Cls Loss: 0.2313, Seg Loss: 0.0972\n",
      "  Batch 390/1428 - Total Loss: 0.4149, Cls Loss: 0.3143, Seg Loss: 0.1006\n",
      "  Batch 400/1428 - Total Loss: 0.1853, Cls Loss: 0.0927, Seg Loss: 0.0926\n",
      "  Batch 410/1428 - Total Loss: 0.9073, Cls Loss: 0.8057, Seg Loss: 0.1016\n",
      "  Batch 420/1428 - Total Loss: 0.1291, Cls Loss: 0.0295, Seg Loss: 0.0996\n",
      "  Batch 430/1428 - Total Loss: 0.1924, Cls Loss: 0.0815, Seg Loss: 0.1110\n",
      "  Batch 440/1428 - Total Loss: 0.2369, Cls Loss: 0.1391, Seg Loss: 0.0979\n",
      "  Batch 450/1428 - Total Loss: 0.2308, Cls Loss: 0.1211, Seg Loss: 0.1097\n",
      "  Batch 460/1428 - Total Loss: 0.3368, Cls Loss: 0.2390, Seg Loss: 0.0978\n",
      "  Batch 470/1428 - Total Loss: 0.1121, Cls Loss: 0.0082, Seg Loss: 0.1039\n",
      "  Batch 480/1428 - Total Loss: 0.1179, Cls Loss: 0.0220, Seg Loss: 0.0959\n",
      "  Batch 490/1428 - Total Loss: 0.2950, Cls Loss: 0.1986, Seg Loss: 0.0964\n",
      "  Batch 500/1428 - Total Loss: 0.1419, Cls Loss: 0.0465, Seg Loss: 0.0955\n",
      "  Batch 510/1428 - Total Loss: 0.3408, Cls Loss: 0.2515, Seg Loss: 0.0893\n",
      "  Batch 520/1428 - Total Loss: 0.1364, Cls Loss: 0.0294, Seg Loss: 0.1070\n",
      "  Batch 530/1428 - Total Loss: 0.1154, Cls Loss: 0.0134, Seg Loss: 0.1020\n",
      "  Batch 540/1428 - Total Loss: 0.1166, Cls Loss: 0.0182, Seg Loss: 0.0984\n",
      "  Batch 550/1428 - Total Loss: 0.3405, Cls Loss: 0.2370, Seg Loss: 0.1035\n",
      "  Batch 560/1428 - Total Loss: 0.1303, Cls Loss: 0.0239, Seg Loss: 0.1064\n",
      "  Batch 570/1428 - Total Loss: 0.1221, Cls Loss: 0.0183, Seg Loss: 0.1038\n",
      "  Batch 580/1428 - Total Loss: 0.1770, Cls Loss: 0.0812, Seg Loss: 0.0959\n",
      "  Batch 590/1428 - Total Loss: 0.4686, Cls Loss: 0.3552, Seg Loss: 0.1135\n",
      "  Batch 600/1428 - Total Loss: 0.7910, Cls Loss: 0.6733, Seg Loss: 0.1177\n",
      "  Batch 610/1428 - Total Loss: 0.1314, Cls Loss: 0.0342, Seg Loss: 0.0972\n",
      "  Batch 620/1428 - Total Loss: 0.1263, Cls Loss: 0.0117, Seg Loss: 0.1146\n",
      "  Batch 630/1428 - Total Loss: 0.1841, Cls Loss: 0.0690, Seg Loss: 0.1151\n",
      "  Batch 640/1428 - Total Loss: 0.1157, Cls Loss: 0.0131, Seg Loss: 0.1026\n",
      "  Batch 650/1428 - Total Loss: 0.1046, Cls Loss: 0.0058, Seg Loss: 0.0988\n",
      "  Batch 660/1428 - Total Loss: 0.1093, Cls Loss: 0.0083, Seg Loss: 0.1010\n",
      "  Batch 670/1428 - Total Loss: 0.2517, Cls Loss: 0.1509, Seg Loss: 0.1008\n",
      "  Batch 680/1428 - Total Loss: 0.1067, Cls Loss: 0.0071, Seg Loss: 0.0997\n",
      "  Batch 690/1428 - Total Loss: 0.1866, Cls Loss: 0.0956, Seg Loss: 0.0910\n",
      "  Batch 700/1428 - Total Loss: 0.1152, Cls Loss: 0.0132, Seg Loss: 0.1020\n",
      "  Batch 710/1428 - Total Loss: 0.1179, Cls Loss: 0.0134, Seg Loss: 0.1045\n",
      "  Batch 720/1428 - Total Loss: 0.3196, Cls Loss: 0.2189, Seg Loss: 0.1006\n",
      "  Batch 730/1428 - Total Loss: 0.1032, Cls Loss: 0.0083, Seg Loss: 0.0949\n",
      "  Batch 740/1428 - Total Loss: 1.5927, Cls Loss: 1.4904, Seg Loss: 0.1023\n",
      "  Batch 750/1428 - Total Loss: 0.1858, Cls Loss: 0.0792, Seg Loss: 0.1066\n",
      "  Batch 760/1428 - Total Loss: 0.3772, Cls Loss: 0.2821, Seg Loss: 0.0951\n",
      "  Batch 770/1428 - Total Loss: 0.1514, Cls Loss: 0.0516, Seg Loss: 0.0998\n",
      "  Batch 780/1428 - Total Loss: 0.1900, Cls Loss: 0.0920, Seg Loss: 0.0979\n",
      "  Batch 790/1428 - Total Loss: 0.2427, Cls Loss: 0.1467, Seg Loss: 0.0960\n",
      "  Batch 800/1428 - Total Loss: 0.2582, Cls Loss: 0.1579, Seg Loss: 0.1003\n",
      "  Batch 810/1428 - Total Loss: 0.2641, Cls Loss: 0.1606, Seg Loss: 0.1035\n",
      "  Batch 820/1428 - Total Loss: 0.4496, Cls Loss: 0.3572, Seg Loss: 0.0924\n",
      "  Batch 830/1428 - Total Loss: 0.8448, Cls Loss: 0.7354, Seg Loss: 0.1094\n",
      "  Batch 840/1428 - Total Loss: 0.3556, Cls Loss: 0.2609, Seg Loss: 0.0947\n",
      "  Batch 850/1428 - Total Loss: 0.3066, Cls Loss: 0.2029, Seg Loss: 0.1037\n",
      "  Batch 860/1428 - Total Loss: 0.1128, Cls Loss: 0.0195, Seg Loss: 0.0934\n",
      "  Batch 870/1428 - Total Loss: 0.1180, Cls Loss: 0.0177, Seg Loss: 0.1003\n",
      "  Batch 880/1428 - Total Loss: 0.1252, Cls Loss: 0.0145, Seg Loss: 0.1107\n",
      "  Batch 890/1428 - Total Loss: 1.7285, Cls Loss: 1.6227, Seg Loss: 0.1058\n",
      "  Batch 900/1428 - Total Loss: 0.1452, Cls Loss: 0.0436, Seg Loss: 0.1016\n",
      "  Batch 910/1428 - Total Loss: 0.2276, Cls Loss: 0.1204, Seg Loss: 0.1072\n",
      "  Batch 920/1428 - Total Loss: 0.2462, Cls Loss: 0.1526, Seg Loss: 0.0935\n",
      "  Batch 930/1428 - Total Loss: 0.1305, Cls Loss: 0.0229, Seg Loss: 0.1076\n",
      "  Batch 940/1428 - Total Loss: 0.1367, Cls Loss: 0.0221, Seg Loss: 0.1145\n",
      "  Batch 950/1428 - Total Loss: 0.6147, Cls Loss: 0.5109, Seg Loss: 0.1038\n",
      "  Batch 960/1428 - Total Loss: 0.3351, Cls Loss: 0.2313, Seg Loss: 0.1039\n",
      "  Batch 970/1428 - Total Loss: 0.1190, Cls Loss: 0.0115, Seg Loss: 0.1076\n",
      "  Batch 980/1428 - Total Loss: 0.1332, Cls Loss: 0.0318, Seg Loss: 0.1014\n",
      "  Batch 990/1428 - Total Loss: 0.3432, Cls Loss: 0.2365, Seg Loss: 0.1067\n",
      "  Batch 1000/1428 - Total Loss: 0.0996, Cls Loss: 0.0088, Seg Loss: 0.0908\n",
      "  Batch 1010/1428 - Total Loss: 0.1281, Cls Loss: 0.0248, Seg Loss: 0.1033\n",
      "  Batch 1020/1428 - Total Loss: 0.1944, Cls Loss: 0.0916, Seg Loss: 0.1028\n",
      "  Batch 1030/1428 - Total Loss: 0.1675, Cls Loss: 0.0652, Seg Loss: 0.1023\n",
      "  Batch 1040/1428 - Total Loss: 0.1516, Cls Loss: 0.0503, Seg Loss: 0.1013\n",
      "  Batch 1050/1428 - Total Loss: 0.3044, Cls Loss: 0.2127, Seg Loss: 0.0917\n",
      "  Batch 1060/1428 - Total Loss: 0.1528, Cls Loss: 0.0469, Seg Loss: 0.1060\n",
      "  Batch 1070/1428 - Total Loss: 0.1115, Cls Loss: 0.0174, Seg Loss: 0.0941\n",
      "  Batch 1080/1428 - Total Loss: 0.1314, Cls Loss: 0.0232, Seg Loss: 0.1083\n",
      "  Batch 1090/1428 - Total Loss: 0.1216, Cls Loss: 0.0235, Seg Loss: 0.0980\n",
      "  Batch 1100/1428 - Total Loss: 0.4728, Cls Loss: 0.3768, Seg Loss: 0.0960\n",
      "  Batch 1110/1428 - Total Loss: 0.1376, Cls Loss: 0.0454, Seg Loss: 0.0922\n",
      "  Batch 1120/1428 - Total Loss: 0.1224, Cls Loss: 0.0235, Seg Loss: 0.0989\n",
      "  Batch 1130/1428 - Total Loss: 0.2680, Cls Loss: 0.1556, Seg Loss: 0.1124\n",
      "  Batch 1140/1428 - Total Loss: 0.1553, Cls Loss: 0.0477, Seg Loss: 0.1076\n",
      "  Batch 1150/1428 - Total Loss: 0.1038, Cls Loss: 0.0125, Seg Loss: 0.0913\n",
      "  Batch 1160/1428 - Total Loss: 0.1296, Cls Loss: 0.0222, Seg Loss: 0.1074\n",
      "  Batch 1170/1428 - Total Loss: 0.2617, Cls Loss: 0.1571, Seg Loss: 0.1046\n",
      "  Batch 1180/1428 - Total Loss: 0.1233, Cls Loss: 0.0069, Seg Loss: 0.1164\n",
      "  Batch 1190/1428 - Total Loss: 0.1634, Cls Loss: 0.0658, Seg Loss: 0.0976\n",
      "  Batch 1200/1428 - Total Loss: 0.1103, Cls Loss: 0.0109, Seg Loss: 0.0994\n",
      "  Batch 1210/1428 - Total Loss: 0.3953, Cls Loss: 0.2814, Seg Loss: 0.1139\n",
      "  Batch 1220/1428 - Total Loss: 0.4567, Cls Loss: 0.3559, Seg Loss: 0.1007\n",
      "  Batch 1230/1428 - Total Loss: 0.2779, Cls Loss: 0.1698, Seg Loss: 0.1081\n",
      "  Batch 1240/1428 - Total Loss: 0.1215, Cls Loss: 0.0163, Seg Loss: 0.1051\n",
      "  Batch 1250/1428 - Total Loss: 0.8050, Cls Loss: 0.7019, Seg Loss: 0.1031\n",
      "  Batch 1260/1428 - Total Loss: 0.2419, Cls Loss: 0.1407, Seg Loss: 0.1012\n",
      "  Batch 1270/1428 - Total Loss: 0.2083, Cls Loss: 0.1105, Seg Loss: 0.0979\n",
      "  Batch 1280/1428 - Total Loss: 0.2808, Cls Loss: 0.1831, Seg Loss: 0.0978\n",
      "  Batch 1290/1428 - Total Loss: 0.1074, Cls Loss: 0.0160, Seg Loss: 0.0913\n",
      "  Batch 1300/1428 - Total Loss: 0.7047, Cls Loss: 0.6102, Seg Loss: 0.0945\n",
      "  Batch 1310/1428 - Total Loss: 0.1282, Cls Loss: 0.0310, Seg Loss: 0.0972\n",
      "  Batch 1320/1428 - Total Loss: 0.1381, Cls Loss: 0.0279, Seg Loss: 0.1102\n",
      "  Batch 1330/1428 - Total Loss: 0.1352, Cls Loss: 0.0322, Seg Loss: 0.1030\n",
      "  Batch 1340/1428 - Total Loss: 0.1082, Cls Loss: 0.0054, Seg Loss: 0.1028\n",
      "  Batch 1350/1428 - Total Loss: 0.2682, Cls Loss: 0.1724, Seg Loss: 0.0958\n",
      "  Batch 1360/1428 - Total Loss: 0.2330, Cls Loss: 0.1296, Seg Loss: 0.1034\n",
      "  Batch 1370/1428 - Total Loss: 0.1107, Cls Loss: 0.0083, Seg Loss: 0.1024\n",
      "  Batch 1380/1428 - Total Loss: 0.2427, Cls Loss: 0.1250, Seg Loss: 0.1178\n",
      "  Batch 1390/1428 - Total Loss: 0.1206, Cls Loss: 0.0239, Seg Loss: 0.0968\n",
      "  Batch 1400/1428 - Total Loss: 0.1398, Cls Loss: 0.0202, Seg Loss: 0.1196\n",
      "  Batch 1410/1428 - Total Loss: 0.2206, Cls Loss: 0.1110, Seg Loss: 0.1096\n",
      "  Batch 1420/1428 - Total Loss: 0.1446, Cls Loss: 0.0466, Seg Loss: 0.0980\n",
      "  Batch 1428/1428 - Total Loss: 0.1197, Cls Loss: 0.0213, Seg Loss: 0.0984\n",
      "Epoch 3 Summary - Avg Total Loss: 0.2491, Avg Cls Loss: 0.1473, Avg Seg Loss: 0.1018\n",
      "\n",
      "Epoch 4/5\n",
      "  Batch 10/1428 - Total Loss: 0.2249, Cls Loss: 0.1165, Seg Loss: 0.1085\n",
      "  Batch 20/1428 - Total Loss: 0.1035, Cls Loss: 0.0093, Seg Loss: 0.0941\n",
      "  Batch 30/1428 - Total Loss: 0.1018, Cls Loss: 0.0047, Seg Loss: 0.0971\n",
      "  Batch 40/1428 - Total Loss: 0.1235, Cls Loss: 0.0150, Seg Loss: 0.1085\n",
      "  Batch 50/1428 - Total Loss: 0.4330, Cls Loss: 0.3298, Seg Loss: 0.1032\n",
      "  Batch 60/1428 - Total Loss: 0.1315, Cls Loss: 0.0343, Seg Loss: 0.0972\n",
      "  Batch 70/1428 - Total Loss: 0.1229, Cls Loss: 0.0192, Seg Loss: 0.1036\n",
      "  Batch 80/1428 - Total Loss: 0.1381, Cls Loss: 0.0350, Seg Loss: 0.1031\n",
      "  Batch 90/1428 - Total Loss: 0.3671, Cls Loss: 0.2834, Seg Loss: 0.0837\n",
      "  Batch 100/1428 - Total Loss: 0.1452, Cls Loss: 0.0413, Seg Loss: 0.1039\n",
      "  Batch 110/1428 - Total Loss: 0.1179, Cls Loss: 0.0260, Seg Loss: 0.0920\n",
      "  Batch 120/1428 - Total Loss: 0.3435, Cls Loss: 0.2441, Seg Loss: 0.0994\n",
      "  Batch 130/1428 - Total Loss: 0.1114, Cls Loss: 0.0041, Seg Loss: 0.1073\n",
      "  Batch 140/1428 - Total Loss: 0.4258, Cls Loss: 0.3010, Seg Loss: 0.1248\n",
      "  Batch 150/1428 - Total Loss: 0.1282, Cls Loss: 0.0268, Seg Loss: 0.1014\n",
      "  Batch 160/1428 - Total Loss: 0.1006, Cls Loss: 0.0057, Seg Loss: 0.0949\n",
      "  Batch 170/1428 - Total Loss: 0.1012, Cls Loss: 0.0054, Seg Loss: 0.0958\n",
      "  Batch 180/1428 - Total Loss: 0.1335, Cls Loss: 0.0322, Seg Loss: 0.1012\n",
      "  Batch 190/1428 - Total Loss: 0.1133, Cls Loss: 0.0100, Seg Loss: 0.1033\n",
      "  Batch 200/1428 - Total Loss: 0.1143, Cls Loss: 0.0178, Seg Loss: 0.0966\n",
      "  Batch 210/1428 - Total Loss: 0.6885, Cls Loss: 0.5981, Seg Loss: 0.0904\n",
      "  Batch 220/1428 - Total Loss: 0.1288, Cls Loss: 0.0270, Seg Loss: 0.1018\n",
      "  Batch 230/1428 - Total Loss: 0.1103, Cls Loss: 0.0052, Seg Loss: 0.1051\n",
      "  Batch 240/1428 - Total Loss: 0.1039, Cls Loss: 0.0101, Seg Loss: 0.0938\n",
      "  Batch 250/1428 - Total Loss: 0.2048, Cls Loss: 0.1002, Seg Loss: 0.1046\n",
      "  Batch 260/1428 - Total Loss: 0.1238, Cls Loss: 0.0232, Seg Loss: 0.1006\n",
      "  Batch 270/1428 - Total Loss: 0.1205, Cls Loss: 0.0114, Seg Loss: 0.1091\n",
      "  Batch 280/1428 - Total Loss: 0.1449, Cls Loss: 0.0490, Seg Loss: 0.0959\n",
      "  Batch 290/1428 - Total Loss: 0.1115, Cls Loss: 0.0152, Seg Loss: 0.0963\n",
      "  Batch 300/1428 - Total Loss: 0.6020, Cls Loss: 0.4958, Seg Loss: 0.1063\n",
      "  Batch 310/1428 - Total Loss: 0.1434, Cls Loss: 0.0448, Seg Loss: 0.0986\n",
      "  Batch 320/1428 - Total Loss: 0.1060, Cls Loss: 0.0086, Seg Loss: 0.0974\n",
      "  Batch 330/1428 - Total Loss: 0.1155, Cls Loss: 0.0113, Seg Loss: 0.1042\n",
      "  Batch 340/1428 - Total Loss: 0.1460, Cls Loss: 0.0390, Seg Loss: 0.1070\n",
      "  Batch 350/1428 - Total Loss: 1.1315, Cls Loss: 1.0245, Seg Loss: 0.1070\n",
      "  Batch 360/1428 - Total Loss: 1.0948, Cls Loss: 0.9931, Seg Loss: 0.1017\n",
      "  Batch 370/1428 - Total Loss: 0.1117, Cls Loss: 0.0165, Seg Loss: 0.0953\n",
      "  Batch 380/1428 - Total Loss: 0.1956, Cls Loss: 0.0897, Seg Loss: 0.1059\n",
      "  Batch 390/1428 - Total Loss: 0.1471, Cls Loss: 0.0532, Seg Loss: 0.0939\n",
      "  Batch 400/1428 - Total Loss: 0.2916, Cls Loss: 0.1957, Seg Loss: 0.0959\n",
      "  Batch 410/1428 - Total Loss: 0.1085, Cls Loss: 0.0047, Seg Loss: 0.1038\n",
      "  Batch 420/1428 - Total Loss: 0.1577, Cls Loss: 0.0558, Seg Loss: 0.1018\n",
      "  Batch 430/1428 - Total Loss: 0.1407, Cls Loss: 0.0406, Seg Loss: 0.1001\n",
      "  Batch 440/1428 - Total Loss: 0.1608, Cls Loss: 0.0611, Seg Loss: 0.0997\n",
      "  Batch 450/1428 - Total Loss: 0.0995, Cls Loss: 0.0058, Seg Loss: 0.0937\n",
      "  Batch 460/1428 - Total Loss: 0.5590, Cls Loss: 0.4627, Seg Loss: 0.0963\n",
      "  Batch 470/1428 - Total Loss: 0.2967, Cls Loss: 0.1956, Seg Loss: 0.1012\n",
      "  Batch 480/1428 - Total Loss: 0.1096, Cls Loss: 0.0037, Seg Loss: 0.1059\n",
      "  Batch 490/1428 - Total Loss: 0.1740, Cls Loss: 0.0733, Seg Loss: 0.1007\n",
      "  Batch 500/1428 - Total Loss: 0.1457, Cls Loss: 0.0517, Seg Loss: 0.0940\n",
      "  Batch 510/1428 - Total Loss: 0.1036, Cls Loss: 0.0054, Seg Loss: 0.0982\n",
      "  Batch 520/1428 - Total Loss: 1.1607, Cls Loss: 1.0681, Seg Loss: 0.0926\n",
      "  Batch 530/1428 - Total Loss: 0.4162, Cls Loss: 0.3178, Seg Loss: 0.0984\n",
      "  Batch 540/1428 - Total Loss: 0.1560, Cls Loss: 0.0499, Seg Loss: 0.1062\n",
      "  Batch 550/1428 - Total Loss: 0.1143, Cls Loss: 0.0225, Seg Loss: 0.0919\n",
      "  Batch 560/1428 - Total Loss: 0.0978, Cls Loss: 0.0023, Seg Loss: 0.0955\n",
      "  Batch 570/1428 - Total Loss: 0.1044, Cls Loss: 0.0075, Seg Loss: 0.0969\n",
      "  Batch 580/1428 - Total Loss: 0.1258, Cls Loss: 0.0205, Seg Loss: 0.1053\n",
      "  Batch 590/1428 - Total Loss: 0.1199, Cls Loss: 0.0193, Seg Loss: 0.1005\n",
      "  Batch 600/1428 - Total Loss: 0.1038, Cls Loss: 0.0098, Seg Loss: 0.0941\n",
      "  Batch 610/1428 - Total Loss: 0.1211, Cls Loss: 0.0122, Seg Loss: 0.1088\n",
      "  Batch 620/1428 - Total Loss: 0.5745, Cls Loss: 0.4709, Seg Loss: 0.1036\n",
      "  Batch 630/1428 - Total Loss: 0.2644, Cls Loss: 0.1521, Seg Loss: 0.1123\n",
      "  Batch 640/1428 - Total Loss: 0.2057, Cls Loss: 0.1082, Seg Loss: 0.0975\n",
      "  Batch 650/1428 - Total Loss: 0.2339, Cls Loss: 0.1300, Seg Loss: 0.1039\n",
      "  Batch 660/1428 - Total Loss: 0.1898, Cls Loss: 0.0897, Seg Loss: 0.1002\n",
      "  Batch 670/1428 - Total Loss: 0.1178, Cls Loss: 0.0198, Seg Loss: 0.0980\n",
      "  Batch 680/1428 - Total Loss: 0.1459, Cls Loss: 0.0293, Seg Loss: 0.1166\n",
      "  Batch 690/1428 - Total Loss: 0.1201, Cls Loss: 0.0120, Seg Loss: 0.1081\n",
      "  Batch 700/1428 - Total Loss: 0.1782, Cls Loss: 0.0699, Seg Loss: 0.1083\n",
      "  Batch 710/1428 - Total Loss: 0.1234, Cls Loss: 0.0238, Seg Loss: 0.0996\n",
      "  Batch 720/1428 - Total Loss: 0.1291, Cls Loss: 0.0186, Seg Loss: 0.1105\n",
      "  Batch 730/1428 - Total Loss: 0.6326, Cls Loss: 0.5349, Seg Loss: 0.0976\n",
      "  Batch 740/1428 - Total Loss: 0.1354, Cls Loss: 0.0503, Seg Loss: 0.0851\n",
      "  Batch 750/1428 - Total Loss: 0.1123, Cls Loss: 0.0151, Seg Loss: 0.0972\n",
      "  Batch 760/1428 - Total Loss: 0.1795, Cls Loss: 0.0798, Seg Loss: 0.0997\n",
      "  Batch 770/1428 - Total Loss: 0.1356, Cls Loss: 0.0426, Seg Loss: 0.0930\n",
      "  Batch 780/1428 - Total Loss: 0.1824, Cls Loss: 0.0790, Seg Loss: 0.1035\n",
      "  Batch 790/1428 - Total Loss: 0.1746, Cls Loss: 0.0717, Seg Loss: 0.1028\n",
      "  Batch 800/1428 - Total Loss: 0.3037, Cls Loss: 0.2086, Seg Loss: 0.0951\n",
      "  Batch 810/1428 - Total Loss: 0.4273, Cls Loss: 0.3237, Seg Loss: 0.1036\n",
      "  Batch 820/1428 - Total Loss: 0.2581, Cls Loss: 0.1632, Seg Loss: 0.0949\n",
      "  Batch 830/1428 - Total Loss: 0.1683, Cls Loss: 0.0680, Seg Loss: 0.1004\n",
      "  Batch 840/1428 - Total Loss: 0.1318, Cls Loss: 0.0333, Seg Loss: 0.0985\n",
      "  Batch 850/1428 - Total Loss: 0.1394, Cls Loss: 0.0409, Seg Loss: 0.0984\n",
      "  Batch 860/1428 - Total Loss: 0.1111, Cls Loss: 0.0142, Seg Loss: 0.0969\n",
      "  Batch 870/1428 - Total Loss: 0.1029, Cls Loss: 0.0080, Seg Loss: 0.0949\n",
      "  Batch 880/1428 - Total Loss: 0.3540, Cls Loss: 0.2583, Seg Loss: 0.0957\n",
      "  Batch 890/1428 - Total Loss: 0.1206, Cls Loss: 0.0180, Seg Loss: 0.1026\n",
      "  Batch 900/1428 - Total Loss: 0.1640, Cls Loss: 0.0687, Seg Loss: 0.0953\n",
      "  Batch 910/1428 - Total Loss: 0.1770, Cls Loss: 0.0358, Seg Loss: 0.1412\n",
      "  Batch 920/1428 - Total Loss: 0.1901, Cls Loss: 0.0859, Seg Loss: 0.1043\n",
      "  Batch 930/1428 - Total Loss: 0.0951, Cls Loss: 0.0024, Seg Loss: 0.0927\n",
      "  Batch 940/1428 - Total Loss: 0.1293, Cls Loss: 0.0357, Seg Loss: 0.0936\n",
      "  Batch 950/1428 - Total Loss: 0.1898, Cls Loss: 0.0922, Seg Loss: 0.0976\n",
      "  Batch 960/1428 - Total Loss: 0.1605, Cls Loss: 0.0684, Seg Loss: 0.0921\n",
      "  Batch 970/1428 - Total Loss: 0.1561, Cls Loss: 0.0542, Seg Loss: 0.1020\n",
      "  Batch 980/1428 - Total Loss: 0.7457, Cls Loss: 0.6493, Seg Loss: 0.0963\n",
      "  Batch 990/1428 - Total Loss: 0.1175, Cls Loss: 0.0143, Seg Loss: 0.1031\n",
      "  Batch 1000/1428 - Total Loss: 0.1472, Cls Loss: 0.0617, Seg Loss: 0.0855\n",
      "  Batch 1010/1428 - Total Loss: 0.1844, Cls Loss: 0.0750, Seg Loss: 0.1095\n",
      "  Batch 1020/1428 - Total Loss: 0.1390, Cls Loss: 0.0424, Seg Loss: 0.0966\n",
      "  Batch 1030/1428 - Total Loss: 0.3814, Cls Loss: 0.2615, Seg Loss: 0.1199\n",
      "  Batch 1040/1428 - Total Loss: 0.5612, Cls Loss: 0.4589, Seg Loss: 0.1023\n",
      "  Batch 1050/1428 - Total Loss: 0.1453, Cls Loss: 0.0458, Seg Loss: 0.0995\n",
      "  Batch 1060/1428 - Total Loss: 0.1457, Cls Loss: 0.0494, Seg Loss: 0.0963\n",
      "  Batch 1070/1428 - Total Loss: 0.1507, Cls Loss: 0.0504, Seg Loss: 0.1004\n",
      "  Batch 1080/1428 - Total Loss: 0.2262, Cls Loss: 0.1246, Seg Loss: 0.1016\n",
      "  Batch 1090/1428 - Total Loss: 0.6235, Cls Loss: 0.5262, Seg Loss: 0.0973\n",
      "  Batch 1100/1428 - Total Loss: 0.2206, Cls Loss: 0.1342, Seg Loss: 0.0863\n",
      "  Batch 1110/1428 - Total Loss: 0.2736, Cls Loss: 0.1660, Seg Loss: 0.1076\n",
      "  Batch 1120/1428 - Total Loss: 0.1024, Cls Loss: 0.0104, Seg Loss: 0.0919\n",
      "  Batch 1130/1428 - Total Loss: 0.1336, Cls Loss: 0.0412, Seg Loss: 0.0924\n",
      "  Batch 1140/1428 - Total Loss: 0.1378, Cls Loss: 0.0424, Seg Loss: 0.0954\n",
      "  Batch 1150/1428 - Total Loss: 0.1873, Cls Loss: 0.0806, Seg Loss: 0.1067\n",
      "  Batch 1160/1428 - Total Loss: 0.1595, Cls Loss: 0.0640, Seg Loss: 0.0955\n",
      "  Batch 1170/1428 - Total Loss: 0.0939, Cls Loss: 0.0044, Seg Loss: 0.0896\n",
      "  Batch 1180/1428 - Total Loss: 0.3248, Cls Loss: 0.2273, Seg Loss: 0.0975\n",
      "  Batch 1190/1428 - Total Loss: 0.4014, Cls Loss: 0.3062, Seg Loss: 0.0951\n",
      "  Batch 1200/1428 - Total Loss: 0.1052, Cls Loss: 0.0045, Seg Loss: 0.1007\n",
      "  Batch 1210/1428 - Total Loss: 0.1038, Cls Loss: 0.0044, Seg Loss: 0.0994\n",
      "  Batch 1220/1428 - Total Loss: 0.2322, Cls Loss: 0.1362, Seg Loss: 0.0960\n",
      "  Batch 1230/1428 - Total Loss: 0.1212, Cls Loss: 0.0185, Seg Loss: 0.1028\n",
      "  Batch 1240/1428 - Total Loss: 0.1038, Cls Loss: 0.0058, Seg Loss: 0.0979\n",
      "  Batch 1250/1428 - Total Loss: 0.1017, Cls Loss: 0.0114, Seg Loss: 0.0903\n",
      "  Batch 1260/1428 - Total Loss: 0.5704, Cls Loss: 0.4731, Seg Loss: 0.0973\n",
      "  Batch 1270/1428 - Total Loss: 1.1859, Cls Loss: 1.0923, Seg Loss: 0.0936\n",
      "  Batch 1280/1428 - Total Loss: 0.1082, Cls Loss: 0.0130, Seg Loss: 0.0952\n",
      "  Batch 1290/1428 - Total Loss: 0.2275, Cls Loss: 0.1179, Seg Loss: 0.1096\n",
      "  Batch 1300/1428 - Total Loss: 0.1773, Cls Loss: 0.0869, Seg Loss: 0.0904\n",
      "  Batch 1310/1428 - Total Loss: 0.1210, Cls Loss: 0.0330, Seg Loss: 0.0880\n",
      "  Batch 1320/1428 - Total Loss: 0.1026, Cls Loss: 0.0154, Seg Loss: 0.0872\n",
      "  Batch 1330/1428 - Total Loss: 0.6920, Cls Loss: 0.5934, Seg Loss: 0.0986\n",
      "  Batch 1340/1428 - Total Loss: 0.3336, Cls Loss: 0.2379, Seg Loss: 0.0958\n",
      "  Batch 1350/1428 - Total Loss: 0.1396, Cls Loss: 0.0455, Seg Loss: 0.0942\n",
      "  Batch 1360/1428 - Total Loss: 0.1061, Cls Loss: 0.0078, Seg Loss: 0.0983\n",
      "  Batch 1370/1428 - Total Loss: 0.1053, Cls Loss: 0.0081, Seg Loss: 0.0972\n",
      "  Batch 1380/1428 - Total Loss: 0.1671, Cls Loss: 0.0732, Seg Loss: 0.0939\n",
      "  Batch 1390/1428 - Total Loss: 0.1805, Cls Loss: 0.0893, Seg Loss: 0.0911\n",
      "  Batch 1400/1428 - Total Loss: 0.1098, Cls Loss: 0.0163, Seg Loss: 0.0935\n",
      "  Batch 1410/1428 - Total Loss: 0.3264, Cls Loss: 0.2311, Seg Loss: 0.0953\n",
      "  Batch 1420/1428 - Total Loss: 0.1241, Cls Loss: 0.0156, Seg Loss: 0.1085\n",
      "  Batch 1428/1428 - Total Loss: 0.1895, Cls Loss: 0.0948, Seg Loss: 0.0946\n",
      "Epoch 4 Summary - Avg Total Loss: 0.2090, Avg Cls Loss: 0.1086, Avg Seg Loss: 0.1004\n",
      "\n",
      "Epoch 5/5\n",
      "  Batch 10/1428 - Total Loss: 0.1284, Cls Loss: 0.0351, Seg Loss: 0.0933\n",
      "  Batch 20/1428 - Total Loss: 0.1754, Cls Loss: 0.0725, Seg Loss: 0.1029\n",
      "  Batch 30/1428 - Total Loss: 0.2071, Cls Loss: 0.1080, Seg Loss: 0.0991\n",
      "  Batch 40/1428 - Total Loss: 0.3680, Cls Loss: 0.2655, Seg Loss: 0.1025\n",
      "  Batch 50/1428 - Total Loss: 0.1875, Cls Loss: 0.0889, Seg Loss: 0.0986\n",
      "  Batch 60/1428 - Total Loss: 0.0944, Cls Loss: 0.0067, Seg Loss: 0.0877\n",
      "  Batch 70/1428 - Total Loss: 0.1433, Cls Loss: 0.0382, Seg Loss: 0.1051\n",
      "  Batch 80/1428 - Total Loss: 0.4027, Cls Loss: 0.2978, Seg Loss: 0.1049\n",
      "  Batch 90/1428 - Total Loss: 0.1214, Cls Loss: 0.0032, Seg Loss: 0.1182\n",
      "  Batch 100/1428 - Total Loss: 0.1120, Cls Loss: 0.0085, Seg Loss: 0.1035\n",
      "  Batch 110/1428 - Total Loss: 0.1069, Cls Loss: 0.0079, Seg Loss: 0.0990\n",
      "  Batch 120/1428 - Total Loss: 0.1112, Cls Loss: 0.0121, Seg Loss: 0.0991\n",
      "  Batch 130/1428 - Total Loss: 0.1044, Cls Loss: 0.0120, Seg Loss: 0.0924\n",
      "  Batch 140/1428 - Total Loss: 0.1179, Cls Loss: 0.0030, Seg Loss: 0.1149\n",
      "  Batch 150/1428 - Total Loss: 0.0979, Cls Loss: 0.0094, Seg Loss: 0.0886\n",
      "  Batch 160/1428 - Total Loss: 0.2798, Cls Loss: 0.1759, Seg Loss: 0.1040\n",
      "  Batch 170/1428 - Total Loss: 0.1047, Cls Loss: 0.0090, Seg Loss: 0.0956\n",
      "  Batch 180/1428 - Total Loss: 0.5377, Cls Loss: 0.4420, Seg Loss: 0.0957\n",
      "  Batch 190/1428 - Total Loss: 0.1997, Cls Loss: 0.1017, Seg Loss: 0.0980\n",
      "  Batch 200/1428 - Total Loss: 0.1148, Cls Loss: 0.0083, Seg Loss: 0.1066\n",
      "  Batch 210/1428 - Total Loss: 0.1288, Cls Loss: 0.0232, Seg Loss: 0.1056\n",
      "  Batch 220/1428 - Total Loss: 0.0961, Cls Loss: 0.0029, Seg Loss: 0.0932\n",
      "  Batch 230/1428 - Total Loss: 0.2002, Cls Loss: 0.0889, Seg Loss: 0.1112\n",
      "  Batch 240/1428 - Total Loss: 0.1025, Cls Loss: 0.0032, Seg Loss: 0.0993\n",
      "  Batch 250/1428 - Total Loss: 0.0965, Cls Loss: 0.0065, Seg Loss: 0.0900\n",
      "  Batch 260/1428 - Total Loss: 0.0999, Cls Loss: 0.0071, Seg Loss: 0.0928\n",
      "  Batch 270/1428 - Total Loss: 0.2503, Cls Loss: 0.1545, Seg Loss: 0.0957\n",
      "  Batch 280/1428 - Total Loss: 0.1082, Cls Loss: 0.0055, Seg Loss: 0.1027\n",
      "  Batch 290/1428 - Total Loss: 0.1029, Cls Loss: 0.0093, Seg Loss: 0.0936\n",
      "  Batch 300/1428 - Total Loss: 0.1019, Cls Loss: 0.0053, Seg Loss: 0.0966\n",
      "  Batch 310/1428 - Total Loss: 0.1021, Cls Loss: 0.0055, Seg Loss: 0.0966\n",
      "  Batch 320/1428 - Total Loss: 0.1271, Cls Loss: 0.0114, Seg Loss: 0.1157\n",
      "  Batch 330/1428 - Total Loss: 0.2872, Cls Loss: 0.1857, Seg Loss: 0.1016\n",
      "  Batch 340/1428 - Total Loss: 0.1214, Cls Loss: 0.0247, Seg Loss: 0.0966\n",
      "  Batch 350/1428 - Total Loss: 0.1198, Cls Loss: 0.0051, Seg Loss: 0.1146\n",
      "  Batch 360/1428 - Total Loss: 0.1132, Cls Loss: 0.0287, Seg Loss: 0.0845\n",
      "  Batch 370/1428 - Total Loss: 0.2243, Cls Loss: 0.1217, Seg Loss: 0.1026\n",
      "  Batch 380/1428 - Total Loss: 0.1684, Cls Loss: 0.0719, Seg Loss: 0.0965\n",
      "  Batch 390/1428 - Total Loss: 0.1110, Cls Loss: 0.0060, Seg Loss: 0.1050\n",
      "  Batch 400/1428 - Total Loss: 0.1243, Cls Loss: 0.0178, Seg Loss: 0.1064\n",
      "  Batch 410/1428 - Total Loss: 0.4458, Cls Loss: 0.3501, Seg Loss: 0.0957\n",
      "  Batch 420/1428 - Total Loss: 0.1620, Cls Loss: 0.0611, Seg Loss: 0.1008\n",
      "  Batch 430/1428 - Total Loss: 0.1220, Cls Loss: 0.0077, Seg Loss: 0.1143\n",
      "  Batch 440/1428 - Total Loss: 0.1298, Cls Loss: 0.0369, Seg Loss: 0.0930\n",
      "  Batch 450/1428 - Total Loss: 0.1559, Cls Loss: 0.0657, Seg Loss: 0.0901\n",
      "  Batch 460/1428 - Total Loss: 0.1110, Cls Loss: 0.0069, Seg Loss: 0.1041\n",
      "  Batch 470/1428 - Total Loss: 0.1192, Cls Loss: 0.0222, Seg Loss: 0.0970\n",
      "  Batch 480/1428 - Total Loss: 0.0964, Cls Loss: 0.0042, Seg Loss: 0.0922\n",
      "  Batch 490/1428 - Total Loss: 0.1073, Cls Loss: 0.0183, Seg Loss: 0.0890\n",
      "  Batch 500/1428 - Total Loss: 0.1023, Cls Loss: 0.0064, Seg Loss: 0.0959\n",
      "  Batch 510/1428 - Total Loss: 0.1304, Cls Loss: 0.0307, Seg Loss: 0.0997\n",
      "  Batch 520/1428 - Total Loss: 0.1464, Cls Loss: 0.0517, Seg Loss: 0.0947\n",
      "  Batch 530/1428 - Total Loss: 0.1457, Cls Loss: 0.0491, Seg Loss: 0.0966\n",
      "  Batch 540/1428 - Total Loss: 0.1151, Cls Loss: 0.0045, Seg Loss: 0.1106\n",
      "  Batch 550/1428 - Total Loss: 0.1111, Cls Loss: 0.0097, Seg Loss: 0.1015\n",
      "  Batch 560/1428 - Total Loss: 0.1291, Cls Loss: 0.0210, Seg Loss: 0.1081\n",
      "  Batch 570/1428 - Total Loss: 0.0934, Cls Loss: 0.0025, Seg Loss: 0.0909\n",
      "  Batch 580/1428 - Total Loss: 0.2888, Cls Loss: 0.1878, Seg Loss: 0.1010\n",
      "  Batch 590/1428 - Total Loss: 0.1182, Cls Loss: 0.0176, Seg Loss: 0.1006\n",
      "  Batch 600/1428 - Total Loss: 0.1047, Cls Loss: 0.0095, Seg Loss: 0.0953\n",
      "  Batch 610/1428 - Total Loss: 0.1147, Cls Loss: 0.0043, Seg Loss: 0.1105\n",
      "  Batch 620/1428 - Total Loss: 0.2144, Cls Loss: 0.1206, Seg Loss: 0.0938\n",
      "  Batch 630/1428 - Total Loss: 0.1447, Cls Loss: 0.0470, Seg Loss: 0.0977\n",
      "  Batch 640/1428 - Total Loss: 0.1485, Cls Loss: 0.0549, Seg Loss: 0.0936\n",
      "  Batch 650/1428 - Total Loss: 0.2559, Cls Loss: 0.1503, Seg Loss: 0.1057\n",
      "  Batch 660/1428 - Total Loss: 0.1121, Cls Loss: 0.0046, Seg Loss: 0.1075\n",
      "  Batch 670/1428 - Total Loss: 0.1045, Cls Loss: 0.0062, Seg Loss: 0.0983\n",
      "  Batch 680/1428 - Total Loss: 0.1097, Cls Loss: 0.0114, Seg Loss: 0.0983\n",
      "  Batch 690/1428 - Total Loss: 0.1050, Cls Loss: 0.0050, Seg Loss: 0.1001\n",
      "  Batch 700/1428 - Total Loss: 0.1105, Cls Loss: 0.0050, Seg Loss: 0.1055\n",
      "  Batch 710/1428 - Total Loss: 0.1167, Cls Loss: 0.0113, Seg Loss: 0.1055\n",
      "  Batch 720/1428 - Total Loss: 0.0956, Cls Loss: 0.0082, Seg Loss: 0.0874\n",
      "  Batch 730/1428 - Total Loss: 0.3032, Cls Loss: 0.2104, Seg Loss: 0.0929\n",
      "  Batch 740/1428 - Total Loss: 0.1550, Cls Loss: 0.0425, Seg Loss: 0.1125\n",
      "  Batch 750/1428 - Total Loss: 0.1084, Cls Loss: 0.0064, Seg Loss: 0.1020\n",
      "  Batch 760/1428 - Total Loss: 0.1039, Cls Loss: 0.0021, Seg Loss: 0.1018\n",
      "  Batch 770/1428 - Total Loss: 0.2901, Cls Loss: 0.1951, Seg Loss: 0.0950\n",
      "  Batch 780/1428 - Total Loss: 0.1179, Cls Loss: 0.0167, Seg Loss: 0.1012\n",
      "  Batch 790/1428 - Total Loss: 0.1022, Cls Loss: 0.0031, Seg Loss: 0.0991\n",
      "  Batch 800/1428 - Total Loss: 0.3623, Cls Loss: 0.2644, Seg Loss: 0.0979\n",
      "  Batch 810/1428 - Total Loss: 0.1041, Cls Loss: 0.0177, Seg Loss: 0.0863\n",
      "  Batch 820/1428 - Total Loss: 0.4527, Cls Loss: 0.3503, Seg Loss: 0.1024\n",
      "  Batch 830/1428 - Total Loss: 0.1385, Cls Loss: 0.0391, Seg Loss: 0.0995\n",
      "  Batch 840/1428 - Total Loss: 0.4947, Cls Loss: 0.3970, Seg Loss: 0.0978\n",
      "  Batch 850/1428 - Total Loss: 0.0997, Cls Loss: 0.0084, Seg Loss: 0.0913\n",
      "  Batch 860/1428 - Total Loss: 0.1228, Cls Loss: 0.0207, Seg Loss: 0.1021\n",
      "  Batch 870/1428 - Total Loss: 0.5267, Cls Loss: 0.4202, Seg Loss: 0.1065\n",
      "  Batch 880/1428 - Total Loss: 0.1081, Cls Loss: 0.0117, Seg Loss: 0.0965\n",
      "  Batch 890/1428 - Total Loss: 0.1383, Cls Loss: 0.0280, Seg Loss: 0.1103\n",
      "  Batch 900/1428 - Total Loss: 0.1187, Cls Loss: 0.0117, Seg Loss: 0.1070\n",
      "  Batch 910/1428 - Total Loss: 0.0943, Cls Loss: 0.0057, Seg Loss: 0.0886\n",
      "  Batch 920/1428 - Total Loss: 0.1111, Cls Loss: 0.0094, Seg Loss: 0.1018\n",
      "  Batch 930/1428 - Total Loss: 0.5531, Cls Loss: 0.4545, Seg Loss: 0.0986\n",
      "  Batch 940/1428 - Total Loss: 0.1111, Cls Loss: 0.0066, Seg Loss: 0.1044\n",
      "  Batch 950/1428 - Total Loss: 0.1264, Cls Loss: 0.0330, Seg Loss: 0.0934\n",
      "  Batch 960/1428 - Total Loss: 0.1000, Cls Loss: 0.0140, Seg Loss: 0.0860\n",
      "  Batch 970/1428 - Total Loss: 0.1098, Cls Loss: 0.0148, Seg Loss: 0.0950\n",
      "  Batch 980/1428 - Total Loss: 0.1438, Cls Loss: 0.0488, Seg Loss: 0.0950\n",
      "  Batch 990/1428 - Total Loss: 0.1536, Cls Loss: 0.0600, Seg Loss: 0.0936\n",
      "  Batch 1000/1428 - Total Loss: 0.1414, Cls Loss: 0.0469, Seg Loss: 0.0945\n",
      "  Batch 1010/1428 - Total Loss: 0.1347, Cls Loss: 0.0439, Seg Loss: 0.0908\n",
      "  Batch 1020/1428 - Total Loss: 0.1086, Cls Loss: 0.0038, Seg Loss: 0.1047\n",
      "  Batch 1030/1428 - Total Loss: 0.4496, Cls Loss: 0.3607, Seg Loss: 0.0889\n",
      "  Batch 1040/1428 - Total Loss: 0.1442, Cls Loss: 0.0500, Seg Loss: 0.0943\n",
      "  Batch 1050/1428 - Total Loss: 0.4791, Cls Loss: 0.3779, Seg Loss: 0.1012\n",
      "  Batch 1060/1428 - Total Loss: 0.1151, Cls Loss: 0.0260, Seg Loss: 0.0891\n",
      "  Batch 1070/1428 - Total Loss: 0.1675, Cls Loss: 0.0672, Seg Loss: 0.1002\n",
      "  Batch 1080/1428 - Total Loss: 0.1108, Cls Loss: 0.0046, Seg Loss: 0.1062\n",
      "  Batch 1090/1428 - Total Loss: 0.1105, Cls Loss: 0.0042, Seg Loss: 0.1063\n",
      "  Batch 1100/1428 - Total Loss: 0.1011, Cls Loss: 0.0032, Seg Loss: 0.0978\n",
      "  Batch 1110/1428 - Total Loss: 0.1298, Cls Loss: 0.0261, Seg Loss: 0.1037\n",
      "  Batch 1120/1428 - Total Loss: 0.0947, Cls Loss: 0.0038, Seg Loss: 0.0909\n",
      "  Batch 1130/1428 - Total Loss: 0.1099, Cls Loss: 0.0049, Seg Loss: 0.1050\n",
      "  Batch 1140/1428 - Total Loss: 0.5771, Cls Loss: 0.4689, Seg Loss: 0.1082\n",
      "  Batch 1150/1428 - Total Loss: 1.2424, Cls Loss: 1.1529, Seg Loss: 0.0895\n",
      "  Batch 1160/1428 - Total Loss: 0.2047, Cls Loss: 0.0782, Seg Loss: 0.1265\n",
      "  Batch 1170/1428 - Total Loss: 0.2073, Cls Loss: 0.1015, Seg Loss: 0.1057\n",
      "  Batch 1180/1428 - Total Loss: 0.1150, Cls Loss: 0.0199, Seg Loss: 0.0950\n",
      "  Batch 1190/1428 - Total Loss: 0.1146, Cls Loss: 0.0040, Seg Loss: 0.1105\n",
      "  Batch 1200/1428 - Total Loss: 0.1223, Cls Loss: 0.0216, Seg Loss: 0.1007\n",
      "  Batch 1210/1428 - Total Loss: 0.0940, Cls Loss: 0.0033, Seg Loss: 0.0907\n",
      "  Batch 1220/1428 - Total Loss: 0.1301, Cls Loss: 0.0212, Seg Loss: 0.1089\n",
      "  Batch 1230/1428 - Total Loss: 0.1095, Cls Loss: 0.0176, Seg Loss: 0.0919\n",
      "  Batch 1240/1428 - Total Loss: 0.1110, Cls Loss: 0.0144, Seg Loss: 0.0967\n",
      "  Batch 1250/1428 - Total Loss: 0.3997, Cls Loss: 0.2980, Seg Loss: 0.1017\n",
      "  Batch 1260/1428 - Total Loss: 0.1726, Cls Loss: 0.0747, Seg Loss: 0.0979\n",
      "  Batch 1270/1428 - Total Loss: 0.2791, Cls Loss: 0.1848, Seg Loss: 0.0944\n",
      "  Batch 1280/1428 - Total Loss: 0.0953, Cls Loss: 0.0058, Seg Loss: 0.0895\n",
      "  Batch 1290/1428 - Total Loss: 0.1126, Cls Loss: 0.0121, Seg Loss: 0.1005\n",
      "  Batch 1300/1428 - Total Loss: 0.1150, Cls Loss: 0.0159, Seg Loss: 0.0991\n",
      "  Batch 1310/1428 - Total Loss: 0.1429, Cls Loss: 0.0290, Seg Loss: 0.1140\n",
      "  Batch 1320/1428 - Total Loss: 0.1427, Cls Loss: 0.0404, Seg Loss: 0.1023\n",
      "  Batch 1330/1428 - Total Loss: 0.1180, Cls Loss: 0.0097, Seg Loss: 0.1084\n",
      "  Batch 1340/1428 - Total Loss: 0.1245, Cls Loss: 0.0240, Seg Loss: 0.1005\n",
      "  Batch 1350/1428 - Total Loss: 0.1049, Cls Loss: 0.0044, Seg Loss: 0.1006\n",
      "  Batch 1360/1428 - Total Loss: 0.1126, Cls Loss: 0.0076, Seg Loss: 0.1050\n",
      "  Batch 1370/1428 - Total Loss: 0.1139, Cls Loss: 0.0099, Seg Loss: 0.1039\n",
      "  Batch 1380/1428 - Total Loss: 0.1121, Cls Loss: 0.0197, Seg Loss: 0.0924\n",
      "  Batch 1390/1428 - Total Loss: 0.1019, Cls Loss: 0.0094, Seg Loss: 0.0925\n",
      "  Batch 1400/1428 - Total Loss: 0.1052, Cls Loss: 0.0111, Seg Loss: 0.0942\n",
      "  Batch 1410/1428 - Total Loss: 0.1568, Cls Loss: 0.0288, Seg Loss: 0.1280\n",
      "  Batch 1420/1428 - Total Loss: 0.2394, Cls Loss: 0.1376, Seg Loss: 0.1018\n",
      "  Batch 1428/1428 - Total Loss: 0.1087, Cls Loss: 0.0066, Seg Loss: 0.1021\n",
      "Epoch 5 Summary - Avg Total Loss: 0.1770, Avg Cls Loss: 0.0766, Avg Seg Loss: 0.1004\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Training the Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Split the dataset: 90% train, 10% test\n",
    "train_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.1, random_state=42)\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Initialize model and training tools\n",
    "model = ShapeClassificationModel(num_classes_list=[6, 5, 5, 3, 2, 2, 3, 2, 3, 6, 2, 2]).to(device)\n",
    "criterion_seg = nn.BCEWithLogitsLoss()\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_cls_loss = 0\n",
    "    total_seg_loss = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    for batch_idx, (images, masks, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seg_out, shape_out = model(images)\n",
    "\n",
    "        loss_seg = criterion_seg(seg_out, masks)\n",
    "        loss_cls = criterion_cls(shape_out, labels)\n",
    "        loss = loss_seg + loss_cls\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_cls_loss += loss_cls.item()\n",
    "        total_seg_loss += loss_seg.item()\n",
    "\n",
    "        # Print every 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print(f\"  Batch {batch_idx+1}/{len(train_loader)} - Total Loss: {loss.item():.4f}, \"\n",
    "                  f\"Cls Loss: {loss_cls.item():.4f}, Seg Loss: {loss_seg.item():.4f}\")\n",
    "\n",
    "    avg_total = total_loss / len(train_loader)\n",
    "    avg_cls = total_cls_loss / len(train_loader)\n",
    "    avg_seg = total_seg_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Summary - Avg Total Loss: {avg_total:.4f}, \"\n",
    "          f\"Avg Cls Loss: {avg_cls:.4f}, Avg Seg Loss: {avg_seg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "15cd0cb4-7798-4b66-9538-b882735a545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as combine_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"combine_model.pth\")\n",
    "print(\"Model saved as combine_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0553becd-bb3d-4cfb-850f-69053ade21f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     pred_mask, pred_labels \u001b[38;5;241m=\u001b[39m model(input_image)\n\u001b[0;32m     36\u001b[0m     pred_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(pred_mask)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m---> 37\u001b[0m     predicted_labels \u001b[38;5;241m=\u001b[39m [out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m pred_labels]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[0;32m     40\u001b[0m image_vis \u001b[38;5;241m=\u001b[39m to_pil_image(image\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import random\n",
    "\n",
    "# Load the model\n",
    "model = ShapeClassificationModel(num_classes_list=[6, 5, 5, 3, 2, 2, 3, 2, 3, 6, 2, 2]).to(device)\n",
    "model.load_state_dict(torch.load(\"combine_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Define label name mappings for each of the 12 shape attributes\n",
    "label_names_all = [\n",
    "    [\"sleeveless\", \"short\", \"elbow\", \"3/4\", \"long\", \"NA\"],\n",
    "    [\"mini\", \"knee\", \"mid\", \"ankle\", \"NA\"],\n",
    "    [\"no socks\", \"ankle\", \"knee\", \"NA\", \"NA\"],  # adjust if fewer classes\n",
    "    [\"no hat\", \"hat\", \"NA\"],\n",
    "    [\"no glasses\", \"glasses\"],\n",
    "    [\"no neckwear\", \"neckwear\"],\n",
    "    [\"none\", \"left\", \"right\"],\n",
    "    [\"no ring\", \"ring\"],\n",
    "    [\"none\", \"belt\", \"strap\"],\n",
    "    [\"round\", \"v\", \"collar\", \"square\", \"halter\", \"NA\"],\n",
    "    [\"no outerwear\", \"outerwear\"],\n",
    "    [\"navel covered\", \"navel exposed\"]\n",
    "]\n",
    "\n",
    "# Select a random test sample\n",
    "idx = random.randint(0, len(test_dataset) - 1)\n",
    "image, mask, labels = test_dataset[idx]\n",
    "\n",
    "# Prepare input\n",
    "input_image = image.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_mask, pred_labels = model(input_image)\n",
    "    pred_mask = torch.sigmoid(pred_mask).squeeze().cpu()\n",
    "    predicted_labels = [out.argmax(dim=1).item() for out in pred_labels]\n",
    "\n",
    "# Visualization\n",
    "image_vis = to_pil_image(image.cpu())\n",
    "true_mask_vis = to_pil_image(mask)\n",
    "pred_mask_vis = to_pil_image((pred_mask > 0.5).float())\n",
    "\n",
    "# Print predicted shape labels\n",
    "print(\"Predicted Shape Attributes:\")\n",
    "for i, pred in enumerate(predicted_labels):\n",
    "    print(f\"{i+1}. {label_names_all[i][pred]}\")\n",
    "\n",
    "# Plot image and masks\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(image_vis)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.imshow(true_mask_vis, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.imshow(pred_mask_vis, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8f3d7-a572-4470-924d-f7c19e356aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
